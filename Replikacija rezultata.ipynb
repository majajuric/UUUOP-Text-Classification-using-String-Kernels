{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce26ca48",
   "metadata": {},
   "source": [
    "Sveučilište u Zagrebu<br>\n",
    "Fakultet elektrotehnike i računarstva\n",
    "\n",
    "## Uvod u znanost o podacima\n",
    "\n",
    "# Replikacija rezultata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3015166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "049dcb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swig in c:\\users\\majajuric\\anaconda3\\lib\\site-packages (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install swig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d3da48",
   "metadata": {},
   "source": [
    "Znanstveni rad opisuje novi način razvrstavanja članaka na temelju jezgrenih funkcija. Jezgrene funkcije predstavljaju umnožak u prostoru značajki. Jezgrene funkcije se koriste za klasifikaciju članaka jer je članke teško vektorizirati, odnosno pretvoriti u vektor značajki.\n",
    "\n",
    "Znanstveni rad opisuje implementaciju jezgre SSK koja navodno ima bolje performanse od standardnih jezgri NGK i WK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7808cdc",
   "metadata": {},
   "source": [
    "## Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8021b0b8",
   "metadata": {},
   "source": [
    "Jezgrene funkcije računaju sličnost između dva primjera. Sličnost se računa kao umnožak u prostoru značajki. Primjeri se samo implicitno preslikavaju u prostor značajki i tamo se množe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70742d6b",
   "metadata": {},
   "source": [
    "### WK kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8285b559",
   "metadata": {},
   "source": [
    "Standardni pristup klasifikaciji teksta preslikava tekst u visokodimenzionalni vektor u kojem svaki element vektora označava prisutnost ili nedostatak neke značajke. Ovakav pristup gubi svu informaciju o redoslijedu riječi te zadržava samo informaciju o frekvenciji pojavljivanja pojmova u dokumentu.\n",
    "\n",
    "Npr.\n",
    "s=\"science is organized knowledge\"\n",
    "t=\"wisdom is organized life\"\n",
    "\n",
    "feature vector = [\"science, is, organized, knowledge, wisdom, life]\n",
    "\n",
    "fi_1 = [1, 1, 1, 1, 0, 0]\n",
    "fi_2 = [0, 1, 1, 0, 1, 1]\n",
    "\n",
    "K(s, t) = [1, 1, 1, 1, 0, 0]*[0, 1, 1, 0, 1, 1] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07e80eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12a731ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "wk_kernel = lambda x, y: wk(x, y)\n",
    "\n",
    "def wkGmats(trainDocs, testDocs):\n",
    "    #defaultanalyzer \"word\" removes non-chars in preprocessing and tokenizes words. does not remove \"markup tokens\"\n",
    "    #stop_words should be \"english\" if not using clean_input_docs()\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                                 tokenizer = None,    \\\n",
    "                                 preprocessor = None, \\\n",
    "                                 stop_words = \"english\", input='content') \n",
    "\n",
    "    train_data_features = vectorizer.fit_transform(trainDocs)\n",
    "    train_data_features = train_data_features.toarray()\n",
    "\n",
    "    transformer = TfidfTransformer(smooth_idf=True)\n",
    "    tfidf = transformer.fit_transform(train_data_features)\n",
    "    tfidf = tfidf.toarray() \n",
    "    #print tfidf\n",
    "    #print \"done\"\n",
    "    #print tfidf.shape\n",
    "    nTrainDocs = len(tfidf)\n",
    "    GmatTrain = np.ones((nTrainDocs,nTrainDocs))\n",
    "\n",
    "    for i in range( 0, nTrainDocs ):\n",
    "        for j in range(0,nTrainDocs):\n",
    "            GmatTrain[i][j] = np.dot(tfidf[i], tfidf[j])\n",
    "            \n",
    "    n_features_train = len(tfidf[0])\n",
    "    \n",
    "    train_data_features = vectorizer.transform(testDocs)\n",
    "    train_data_features = train_data_features.toarray()\n",
    "\n",
    "    transformer = TfidfTransformer(smooth_idf=True)\n",
    "    tfidfTest = transformer.fit_transform(train_data_features)\n",
    "    tfidfTest = tfidfTest.toarray() \n",
    "    #print tfidf\n",
    "    #print \"done\"\n",
    "    #print tfidf.shape\n",
    "    nTestDocs = len(tfidfTest)\n",
    "    GmatTest = np.ones((nTestDocs,nTrainDocs))\n",
    "\n",
    "    for i in range( 0, nTestDocs ):\n",
    "        for j in range(0,nTrainDocs):\n",
    "            GmatTest[i][j] = np.dot(tfidfTest[i], tfidf[j])\n",
    "\n",
    "    # print \"Trainmean: \", GmatTrain.mean()\n",
    "    # print \"Testmean: \", GmatTest.mean()\n",
    "    \n",
    "    return GmatTrain, GmatTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7637a028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting WK, creating bag of words...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14851129125610232"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[wk_train_gram_mat, wk_test_gram_mat] = wkGmats([\"science is organized knowledge\"], [\"wisdom is organized life\"])\n",
    "\n",
    "wk.wk(\"science is organized knowledge\",\"wisdom is organized life\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750371e6",
   "metadata": {},
   "source": [
    "### NGK kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7321002f",
   "metadata": {},
   "source": [
    "NGK jezgra koristi n-grams. N-grams daju n susjednih slova nekog stringa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529ef40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ngk\n",
    "\n",
    "doc1, doc2 = \"science is organized knowledge\", \"wisdom is organized life\"\n",
    "print(ngk.ngk(doc1, doc2))\n",
    "print(ngk.ngk(doc1, doc2, n=7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f5260b",
   "metadata": {},
   "source": [
    "### SSK kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e34b2ee",
   "metadata": {},
   "source": [
    "Cijeli dokument se promatra kao jedan dugačak sequence. Prostor značajki u ovom slučaju je set svih ne nužno susjednih substringova od k simbola. Dva članka su to sličniji što imaju više zajedničkih takvih substringova.\n",
    "\n",
    "Sličnost se računa u ovisnosti o lambdi koja mjeri težinu u ovisnosti u duljini i uzastopnosti charactera svakog subsequenca iz jednog dokumenta u drugom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ab86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a737b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssk_compute_train_gram(docs, kernel=None):\n",
    "    n = len(docs)\n",
    "    gram = np.ones((n, n))\n",
    "    for x in range(n):\n",
    "        print('{0:.2f}%'.format(x / n))\n",
    "        for y in range(x + 1, n):\n",
    "            gram[x, y] = kernel(docs[x], docs[y])\n",
    "            gram[y, x] = gram[x, y]\n",
    "    return gram  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3670d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssk_compute_test_gram(test, train, kernel=None):\n",
    "    gram = np.zeros((len(test), len(train)))\n",
    "    for x in range(len(test)):\n",
    "        print('{0:.2f}%'.format(x / len(test)))\n",
    "        for y in range(len(train)):\n",
    "            gram[x, y] = kernel(test[x], train[y])\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a97876a",
   "metadata": {},
   "source": [
    "### Priprema podataka\n",
    "U članku piše da su sve riječi u body-jima svih članaka pretvorene u lowercase. Također, uklonjene su sve *stopwords*, a interpunkcijski znakovi zamijenjeni su razmacima. Također, bitni su nam samo stupci TOPICS i BODY tako da ostale možemo izbaciti.\n",
    "\n",
    "U članku piše da su zadržali samo stem riječi. Pokušala sam to napraviti, ali javlja neku grešku s nltk --> pokušati opet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7351c0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPICS</th>\n",
       "      <th>BODY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['cocoa']</td>\n",
       "      <td>showers continued throughout week bahia cocoa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['grain', 'wheat', 'corn', 'barley', 'oat', 's...</td>\n",
       "      <td>u agriculture department reported farmer owned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['veg-oil', 'linseed', 'lin-oil', 'soy-oil', '...</td>\n",
       "      <td>argentine grain board figures show crop regist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['earn']</td>\n",
       "      <td>champion products inc said board directors app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['acq']</td>\n",
       "      <td>computer terminal systems inc said completed s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              TOPICS  \\\n",
       "0                                          ['cocoa']   \n",
       "1  ['grain', 'wheat', 'corn', 'barley', 'oat', 's...   \n",
       "2  ['veg-oil', 'linseed', 'lin-oil', 'soy-oil', '...   \n",
       "3                                           ['earn']   \n",
       "4                                            ['acq']   \n",
       "\n",
       "                                                BODY  \n",
       "0  showers continued throughout week bahia cocoa ...  \n",
       "1  u agriculture department reported farmer owned...  \n",
       "2  argentine grain board figures show crop regist...  \n",
       "3  champion products inc said board directors app...  \n",
       "4  computer terminal systems inc said completed s...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clanci_stripped = pd.read_csv(\"clanci_stripped.csv\", index_col = 0)\n",
    "clanci_stripped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7176c772",
   "metadata": {},
   "source": [
    "Razdvajamo BODY-je po TOPICS-ima tako da u TOPICS nije lista nego samo jedna vrijednost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "393bdfb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPICS</th>\n",
       "      <th>BODY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'cocoa'</td>\n",
       "      <td>showers continued throughout week bahia cocoa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'grain'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'wheat'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'corn'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'barley'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'oat'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'sorghum'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'veg-oil'</td>\n",
       "      <td>argentine grain board figures show crop regist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'linseed'</td>\n",
       "      <td>argentine grain board figures show crop regist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'lin-oil'</td>\n",
       "      <td>argentine grain board figures show crop regist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TOPICS                                               BODY\n",
       "0     'cocoa'  showers continued throughout week bahia cocoa ...\n",
       "1     'grain'  agriculture department reported farmer owned r...\n",
       "2     'wheat'  agriculture department reported farmer owned r...\n",
       "3      'corn'  agriculture department reported farmer owned r...\n",
       "4    'barley'  agriculture department reported farmer owned r...\n",
       "5       'oat'  agriculture department reported farmer owned r...\n",
       "6   'sorghum'  agriculture department reported farmer owned r...\n",
       "7   'veg-oil'  argentine grain board figures show crop regist...\n",
       "8   'linseed'  argentine grain board figures show crop regist...\n",
       "9   'lin-oil'  argentine grain board figures show crop regist..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clanci_stripped = clanci_stripped.loc[:, [\"TOPICS\", \"BODY\"]]\n",
    "clanci_stripped = clanci_stripped.loc[clanci_stripped.TOPICS.notnull(), :]\n",
    "#print(clanci.head(n=10))\n",
    "\n",
    "mapa = {'TOPICS': [], 'BODY': []}\n",
    "for index, row in clanci_stripped.iterrows():\n",
    "    topics = row.TOPICS.split(\",\")\n",
    "    for topic in topics:\n",
    "        topic = topic.replace('[', \"\")\n",
    "        topic = topic.replace(\"]\", \"\")\n",
    "        if mapa['TOPICS'] is None:\n",
    "            mapa['TOPICS'] = [topic]\n",
    "        else:\n",
    "            mapa['TOPICS'].append(topic)\n",
    "            \n",
    "        body = row.BODY\n",
    "        unfiltered_body = \"\"\n",
    "        for word in body.split(\" \"):\n",
    "            if len(word) > 3:\n",
    "                unfiltered_body+=word\n",
    "                unfiltered_body+=\" \"\n",
    "        filtered_body = \"\"\n",
    "        for character in unfiltered_body:\n",
    "            if (character.isalnum()) or (character == ' '):\n",
    "                filtered_body += character\n",
    "        filtered_body = filtered_body.replace('[^a-zA-Z]', \" \")\n",
    "        filtered_body = filtered_body.replace(' [ ]+', ' ')\n",
    "        \n",
    "        if mapa['BODY'] is None:\n",
    "            mapa['BODY'] = [filtered_body]\n",
    "        else:\n",
    "            mapa['BODY'].append(filtered_body)\n",
    "            \n",
    "dataframe = pd.DataFrame(mapa)\n",
    "dataframe.to_csv(\"clanci_split.csv\")\n",
    "dataframe.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bca78e2",
   "metadata": {},
   "source": [
    "## Experimental Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5bf472",
   "metadata": {},
   "source": [
    "Ciljevi eksperimenata su:\n",
    "- proučavati utjecaj promjene parametara k(duljina) i $\\lambda$(težina)\n",
    "- uočiti prednosti kombiniranja različitih jezgri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aaf77b",
   "metadata": {},
   "source": [
    "### Podjela podataka u train i test skup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6d1c8",
   "metadata": {},
   "source": [
    "Eksperimenti su provedeni samo na dijelu Reuters seta. U članku piše da je subset bio veličine 470 dokumenata, od čega je 380 bilo korišteno za treniranje, a 90 za ispitivanje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bad638",
   "metadata": {},
   "source": [
    "U eksperimentu su odabrane kategorije \"earn\", \"acq\", \"crude\" i \"corn\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "earn_clanci = dataframe[dataframe.TOPICS.str.contains(\"earn\")]\n",
    "acq_clanci = dataframe[dataframe.TOPICS.str.contains(\"acq\")]\n",
    "crude_clanci = dataframe[dataframe.TOPICS.str.contains(\"crude\")]\n",
    "corn_clanci = dataframe[dataframe.TOPICS.str.contains(\"corn\")]\n",
    "\n",
    "clanci = [earn_clanci, acq_clanci, crude_clanci, corn_clanci]\n",
    "clanci.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1e278",
   "metadata": {},
   "source": [
    "Navedeno je da je broj članaka za pojedinu kategoriju za učenje (ispitivanje) sljedeći:\n",
    "1. earn 152 (40)\n",
    "2. acquisition 114 (25)\n",
    "3. crude 76 (15)\n",
    "4. corn 38 (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f154e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def give_train_test_split(give_train):\n",
    "    [earn_tr, earn_te] = train_test_split(earn_clanci, train_size=152/len(earn_clanci), test_size=40/len(earn_clanci))\n",
    "    [acq_tr, acq_te] = train_test_split(acq_clanci, train_size=114/len(acq_clanci), test_size=25/len(acq_clanci))\n",
    "    [crude_tr, crude_te] = train_test_split(crude_clanci, train_size=76/len(crude_clanci), test_size=15/len(crude_clanci))\n",
    "    [corn_tr, corn_te] = train_test_split(corn_clanci, train_size=38/len(corn_clanci), test_size=10/len(corn_clanci))\n",
    "\n",
    "    y_train = []\n",
    "    y_train.extend(['earn' for i in range(0, len(earn_tr))])\n",
    "    y_train.extend(['acq' for i in range(0, len(acq_tr))])\n",
    "    y_train.extend(['crude' for i in range(0, len(crude_tr))])\n",
    "    y_train.extend(['corn' for i in range(0, len(corn_tr))])\n",
    "    y_train = np.array(y_train)\n",
    "    #print(y_train)\n",
    "\n",
    "    y_test = []\n",
    "    y_test.extend(['earn' for i in range(0, len(earn_te))])\n",
    "    y_test.extend(['acq' for i in range(0, len(acq_te))])\n",
    "    y_test.extend(['crude' for i in range(0, len(crude_te))])\n",
    "    y_test.extend(['corn' for i in range(0, len(corn_te))])\n",
    "    y_test = np.array(y_test)\n",
    "    #print(y_test)\n",
    "\n",
    "    clanci_test = [earn_te, acq_te, crude_te, corn_te]\n",
    "    clanci_test = pd.concat(clanci_test)\n",
    "    clanci_train = [earn_tr, acq_tr, crude_tr, corn_tr]\n",
    "    clanci_train = pd.concat(clanci_train)\n",
    "    #clanci_train #.to_csv(\"clanci_train.csv\")\n",
    "    \n",
    "    earn_test=[]\n",
    "    acq_test=[]\n",
    "    crude_test=[]\n",
    "    corn_test=[]\n",
    "    for index, row in earn_te.iterrows():\n",
    "        earn_test.append(row['BODY'])\n",
    "    for index, row in acq_te.iterrows():\n",
    "        acq_test.append(row['BODY'])\n",
    "    for index, row in crude_te.iterrows():\n",
    "        crude_test.append(row['BODY'])\n",
    "    for index, row in corn_te.iterrows():\n",
    "        corn_test.append(row['BODY'])\n",
    "    \n",
    "    treniranje_parovi = []\n",
    "    treniranje = []\n",
    "    i = 0\n",
    "    for index, row in clanci_train.iterrows():\n",
    "        par = []\n",
    "        par = [row['BODY'], y_train[i]]\n",
    "        treniranje.append(row['BODY'])\n",
    "        treniranje_parovi.append(par)\n",
    "\n",
    "    testiranje = []\n",
    "    for index, row in clanci_test.iterrows():\n",
    "        testiranje.append(row['BODY'])\n",
    "    \n",
    "    if give_train:\n",
    "        return [treniranje, y_train]\n",
    "    else:\n",
    "        return [earn_test, acq_test, crude_test, corn_test, testiranje, y_test]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee86bf1",
   "metadata": {},
   "source": [
    "### Effectiveness of Varying Sequence Length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc05ef",
   "metadata": {},
   "source": [
    "U ovom dijelu promatramo kako parametar duljine subsequenca, k, utječe na točnost modela. Za svaku vrijednost k, eksperiment je proveden 10 puta i onda su dobivene vrijednosti mean i sd. Lambda je postavljen na 0.5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a8227f",
   "metadata": {},
   "source": [
    "Kako je računanje za SSK jako sporo, kod njega sam izostavila provođenje eksperimenta 10 puta pa se on provodi samo jednom. Za NGK se provodi 10 puta i vrijednosti evaluacije rezultata su uprosječene."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e654a",
   "metadata": {},
   "source": [
    "Stvorimo listu u koju stavljamo [category, ime ljuske, length, f1_mean, f1_std, precision_mean, precision_std, recall_mean, recall_std]. Od te liste kasnije stvorimo dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f4615",
   "metadata": {},
   "source": [
    "#### Evaluacija SSK jezgre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a9cda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ispisuje tablicu kao sto je u radu\n",
    "def ssk_evaluation(category, k_range=[5], lambd_range=[0.5]):\n",
    "    rezultat_lista = []\n",
    "    [treniranje, y_train] = give_train_test_split(True)\n",
    "    for k in k_range:\n",
    "        for lambd in lambd_range:\n",
    "            print(category, k)\n",
    "            lista_u_ovom_koraku = []\n",
    "            lista_u_ovom_koraku.append(category)\n",
    "            lista_u_ovom_koraku.append(\"SSK\")\n",
    "            f1 = []\n",
    "            precision = []\n",
    "            recall = []\n",
    "            ssk_kernel = lambda x, y: ssk.ssk(x, y, k, lambd)\n",
    "            train_gram = ssk_compute_train_gram(treniranje, kernel=ssk_kernel)\n",
    "            #for i in range(0, 10):\n",
    "                #treniranje jezgre\n",
    "            #[treniranje, y_train] = give_train_test_split(True)\n",
    "            #train_gram = ssk_compute_train_gram(treniranje, kernel=ssk_kernel)\n",
    "            print(\"\\t---1---\")\n",
    "            [earn_test, acq_test, crude_test, corn_test, _, _] = give_train_test_split(False)\n",
    "            if(category==\"earn\"):\n",
    "                X_test = earn_test\n",
    "                y_true = np.array(['earn' for i in range(0, len(earn_test))])\n",
    "            elif category == \"acq\":\n",
    "                X_test = acq_test\n",
    "                y_true = np.array(['acq' for i in range(0, len(acq_test))])\n",
    "            elif category == \"crude\":\n",
    "                X_test = crude_test\n",
    "                y_true = np.array(['crude' for i in range(0, len(crude_test))])\n",
    "            else:\n",
    "                X_test = corn_test\n",
    "                y_true = np.array(['corn' for i in range(0, len(corn_test))])\n",
    "\n",
    "            test_gram = ssk_compute_test_gram(X_test, treniranje, kernel=ssk_kernel)\n",
    "            print(\"\\t---2---\")\n",
    "            clf = SVC(kernel='precomputed')\n",
    "            clf.fit(train_gram, y_train)\n",
    "            print(\"\\t---3---\")\n",
    "            # predikcija\n",
    "            y_pred = clf.predict(test_gram)\n",
    "            print(\"\\t---4---\")\n",
    "            f1.append(f1_score(y_true, y_pred, average='micro'))\n",
    "            precision.append(precision_score(y_true, y_pred, average='micro'))\n",
    "            recall.append(recall_score(y_true, y_pred, average='micro'))\n",
    "            \n",
    "        if len(k_range) == 1:\n",
    "            lista_u_ovom_koraku.append(lambd)\n",
    "        else:\n",
    "            lista_u_ovom_koraku.append(k)\n",
    "            \n",
    "        lista_u_ovom_koraku.append(round(np.mean(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(recall), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(recall), 3))\n",
    "        \n",
    "        rezultat_lista.append(lista_u_ovom_koraku)\n",
    "        lista_u_ovom_koraku.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    return rezultat_lista\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c014de0d",
   "metadata": {},
   "source": [
    "#### Evaluacija NGK jezgre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76f093fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngk_evaluation(category, k_range=[5],):\n",
    "    rezultat_lista = []\n",
    "    [treniranje, y_train] = give_train_test_split(True)\n",
    "    for k in k_range:\n",
    "        lista_u_ovom_koraku = []\n",
    "        lista_u_ovom_koraku.append(category)\n",
    "        lista_u_ovom_koraku.append(\"NGK\")\n",
    "        print(k)\n",
    "        f1 = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        for i in range(0, 10):\n",
    "            #treniranje jezgre\n",
    "            #[treniranje, y_train] = give_train_test_split(True)\n",
    "            [earn_test, acq_test, crude_test, corn_test, _, _] = give_train_test_split(False)\n",
    "            if(category==\"earn\"):\n",
    "                X_test = earn_test\n",
    "                y_true = np.array(['earn' for i in range(0, len(earn_test))])\n",
    "            elif category == \"acq\":\n",
    "                X_test = acq_test\n",
    "                y_true = np.array(['acq' for i in range(0, len(acq_test))])\n",
    "            elif category == \"crude\":\n",
    "                X_test = crude_test\n",
    "                y_true = np.array(['crude' for i in range(0, len(crude_test))])\n",
    "            else:\n",
    "                X_test = corn_test\n",
    "                y_true = np.array(['corn' for i in range(0, len(corn_test))])\n",
    "\n",
    "            train_gram, test_gram = ngk.ngkGmats(treniranje, X_test, n=k)\n",
    "            clf = SVC(kernel='precomputed')\n",
    "            clf.fit(train_gram, y_train)\n",
    "            y_pred = clf.predict(test_gram)\n",
    "            f1.append(round(f1_score(y_true, y_pred, average='micro'), 3))\n",
    "            precision.append(round(precision_score(y_true, y_pred, average='micro'), 3))\n",
    "            recall.append(round(recall_score(y_true, y_pred, average='micro'), 3))\n",
    "        \n",
    "        if len(k_range) == 1:\n",
    "            lista_u_ovom_koraku.append(lambd)\n",
    "        else:\n",
    "            lista_u_ovom_koraku.append(k)\n",
    "        lista_u_ovom_koraku.append(round(np.mean(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(recall), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(recall), 3))\n",
    "        #print(lista_u_ovom_koraku)\n",
    "    return rezultat_lista\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b794a46",
   "metadata": {},
   "source": [
    "#### Evaluacija WK jezgre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f47f9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wk_evaluation(category):\n",
    "    rezultat_lista = []\n",
    "    rezultat_lista.append(category)\n",
    "    rezultat_lista.append(\"WK\")\n",
    "\n",
    "    f1 = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    \n",
    "    [treniranje, y_train] = give_train_test_split(True)\n",
    "    for i in range(0, 10):\n",
    "        print(category, i)\n",
    "        #treniranje jezgre\n",
    "        #[treniranje, y_train] = give_train_test_split(True)\n",
    "        [earn_test, acq_test, crude_test, corn_test, _, _] = give_train_test_split(False)\n",
    "        if(category==\"earn\"):\n",
    "            X_test = earn_test\n",
    "            y_true = np.array(['earn' for i in range(0, len(earn_test))])\n",
    "        elif category == \"acq\":\n",
    "            X_test = acq_test\n",
    "            y_true = np.array(['acq' for i in range(0, len(acq_test))])\n",
    "        elif category == \"crude\":\n",
    "            X_test = crude_test\n",
    "            y_true = np.array(['crude' for i in range(0, len(crude_test))])\n",
    "        else:\n",
    "            X_test = corn_test\n",
    "            y_true = np.array(['corn' for i in range(0, len(corn_test))])\n",
    "\n",
    "        wk_kernel = lambda x, y: wk(x, y)\n",
    "        [wk_train_gram, wk_test_gram] = wkGmats(treniranje, X_test)\n",
    "        clf = SVC(kernel='precomputed')\n",
    "        clf.fit(wk_train_gram, y_train)\n",
    "        y_pred = clf.predict(wk_test_gram)\n",
    "        f1.append(round(f1_score(y_true, y_pred, average='micro'), 3))\n",
    "        precision.append(round(precision_score(y_true, y_pred, average='micro'), 3))\n",
    "        recall.append(round(recall_score(y_true, y_pred, average='micro'), 3))\n",
    "        \n",
    "    rezultat_lista.append(0)\n",
    "    rezultat_lista.append(round(np.mean(f1), 3))\n",
    "    rezultat_lista.append(round(np.std(f1), 3))\n",
    "    rezultat_lista.append(round(np.mean(precision), 3))\n",
    "    rezultat_lista.append(round(np.std(precision), 3))\n",
    "    rezultat_lista.append(round(np.mean(recall), 3))\n",
    "    rezultat_lista.append(round(np.std(recall), 3))\n",
    "    \n",
    "    return [rezultat_lista]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "21779125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acq 3\n",
      "0.00%\n",
      "0.00%\n",
      "0.01%\n",
      "0.01%\n",
      "0.01%\n",
      "0.01%\n",
      "0.02%\n",
      "0.02%\n",
      "0.02%\n",
      "0.02%\n",
      "0.03%\n",
      "0.03%\n",
      "0.03%\n",
      "0.03%\n",
      "0.04%\n",
      "0.04%\n",
      "0.04%\n",
      "0.04%\n",
      "0.05%\n",
      "0.05%\n",
      "0.05%\n",
      "0.06%\n",
      "0.06%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 54>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m     varying_sequence_length \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rezultat, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mime ljuske\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_std\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision_std\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall_std\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     52\u001b[0m     varying_sequence_length\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvarying_sequence_length.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 54\u001b[0m \u001b[43mevaluation_for_varying_sequence_lengths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [78]\u001b[0m, in \u001b[0;36mevaluation_for_varying_sequence_lengths\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluation_for_varying_sequence_lengths\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#rezultat = []\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m#varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m#varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     rezultat \u001b[38;5;241m=\u001b[39m \u001b[43mssk_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43macq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     varying_sequence_length \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rezultat, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mime ljuske\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_std\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision_std\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall_std\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     28\u001b[0m     varying_sequence_length\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvarying_sequence_length.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [77]\u001b[0m, in \u001b[0;36mssk_evaluation\u001b[1;34m(category, k_range, lambd_range)\u001b[0m\n\u001b[0;32m     13\u001b[0m recall \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m ssk_kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, y: ssk\u001b[38;5;241m.\u001b[39mssk(x, y, k, lambd)\n\u001b[1;32m---> 15\u001b[0m train_gram \u001b[38;5;241m=\u001b[39m \u001b[43mssk_compute_train_gram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtreniranje\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssk_kernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#for i in range(0, 10):\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m#treniranje jezgre\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#[treniranje, y_train] = give_train_test_split(True)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#train_gram = ssk_compute_train_gram(treniranje, kernel=ssk_kernel)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m---1---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mssk_compute_train_gram\u001b[1;34m(docs, kernel)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0:.2f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x \u001b[38;5;241m/\u001b[39m n))\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, n):\n\u001b[1;32m----> 7\u001b[0m         gram[x, y] \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m         gram[y, x] \u001b[38;5;241m=\u001b[39m gram[x, y]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gram\n",
      "Input \u001b[1;32mIn [77]\u001b[0m, in \u001b[0;36mssk_evaluation.<locals>.<lambda>\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     12\u001b[0m precision \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m recall \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 14\u001b[0m ssk_kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, y: \u001b[43mssk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m train_gram \u001b[38;5;241m=\u001b[39m ssk_compute_train_gram(treniranje, kernel\u001b[38;5;241m=\u001b[39mssk_kernel)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#for i in range(0, 10):\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m#treniranje jezgre\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#[treniranje, y_train] = give_train_test_split(True)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#train_gram = ssk_compute_train_gram(treniranje, kernel=ssk_kernel)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluation_for_varying_sequence_lengths():\n",
    "    #rezultat = []\n",
    "    #varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_sequence_length.to_csv(\"varying_sequence_length.csv\")\n",
    "    \n",
    "    #rezultat = ngk_evaluation(\"earn\", k_range=[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
    "    #varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    #rezultat = ssk_evaluation(\"earn\", k_range=[3, 5, 7, 14])\n",
    "    #varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = wk_evaluation(\"earn\")\n",
    "    varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    #rezultat = ngk_evaluation(\"acq\", k_range=[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
    "    #varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ssk_evaluation(\"acq\", k_range=[3, 5, 7, 14])\n",
    "    varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = wk_evaluation(\"acq\")\n",
    "    varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    #rezultat = ssk_evaluation(\"crude\", k_range=[3, 5, 7, 14])\n",
    "    #varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    #rezultat = ngk_evaluation(\"crude\", k_range=[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
    "    #varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = wk_evaluation(\"crude\")\n",
    "    varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    #rezultat = ngk_evaluation(\"corn\", k_range=[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
    "    #varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    #rezultat = ssk_evaluation(\"corn\", k_range=[3, 5, 7, 14])\n",
    "    #varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "\n",
    "    rezultat = wk_evaluation(\"corn\")\n",
    "    varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "evaluation_for_varying_sequence_lengths()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c0bdbf",
   "metadata": {},
   "source": [
    "#### Usporedba rezultata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5568c203",
   "metadata": {},
   "source": [
    "Radi brzine izvođenja, nisam računala za sve k kao što je u znanstvenom radu. Ali se može uočiti da SSK najbolje radi za male i srednje velike k (otprilike 4-7). Parametar k može se postaviti unaprijed unakrsnom provjerom tako da maksimizira točnost (minimizira pogrešku) na skupu za provjeru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "469adbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MajaJuric\\AppData\\Local\\Temp\\ipykernel_5732\\3951764689.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>ime ljuske</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>earn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>3</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>earn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>4</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>earn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>5</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>earn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>6</th>\n",
       "      <td>0.930</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>earn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>7</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>earn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>8</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>earn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>9</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>earn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>10</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>earn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>11</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>earn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>12</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>earn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>13</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>earn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>14</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>acq</th>\n",
       "      <th>NGK</th>\n",
       "      <th>3</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>acq</th>\n",
       "      <th>NGK</th>\n",
       "      <th>4</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>acq</th>\n",
       "      <th>NGK</th>\n",
       "      <th>5</th>\n",
       "      <td>0.964</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>acq</th>\n",
       "      <th>NGK</th>\n",
       "      <th>6</th>\n",
       "      <td>0.948</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>acq</th>\n",
       "      <th>NGK</th>\n",
       "      <th>7</th>\n",
       "      <td>0.956</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>acq</th>\n",
       "      <th>NGK</th>\n",
       "      <th>8</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>acq</th>\n",
       "      <th>NGK</th>\n",
       "      <th>9</th>\n",
       "      <td>0.948</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>acq</th>\n",
       "      <th>NGK</th>\n",
       "      <th>10</th>\n",
       "      <td>0.960</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>acq</th>\n",
       "      <th>NGK</th>\n",
       "      <th>11</th>\n",
       "      <td>0.964</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>acq</th>\n",
       "      <th>NGK</th>\n",
       "      <th>12</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>acq</th>\n",
       "      <th>NGK</th>\n",
       "      <th>13</th>\n",
       "      <td>0.960</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>acq</th>\n",
       "      <th>NGK</th>\n",
       "      <th>14</th>\n",
       "      <td>0.960</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>crude</th>\n",
       "      <th>NGK</th>\n",
       "      <th>3</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>crude</th>\n",
       "      <th>NGK</th>\n",
       "      <th>4</th>\n",
       "      <td>0.947</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>crude</th>\n",
       "      <th>NGK</th>\n",
       "      <th>5</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>crude</th>\n",
       "      <th>NGK</th>\n",
       "      <th>6</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>crude</th>\n",
       "      <th>NGK</th>\n",
       "      <th>7</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>crude</th>\n",
       "      <th>NGK</th>\n",
       "      <th>8</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>crude</th>\n",
       "      <th>NGK</th>\n",
       "      <th>9</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>crude</th>\n",
       "      <th>NGK</th>\n",
       "      <th>10</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>crude</th>\n",
       "      <th>NGK</th>\n",
       "      <th>11</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>crude</th>\n",
       "      <th>NGK</th>\n",
       "      <th>12</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>crude</th>\n",
       "      <th>NGK</th>\n",
       "      <th>13</th>\n",
       "      <td>0.773</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>crude</th>\n",
       "      <th>NGK</th>\n",
       "      <th>14</th>\n",
       "      <td>0.633</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>corn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>3</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>corn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>4</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>corn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>5</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>corn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>6</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>corn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>7</th>\n",
       "      <td>0.780</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>corn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>8</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>corn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>9</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>corn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>10</th>\n",
       "      <td>0.690</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>corn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>11</th>\n",
       "      <td>0.540</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>corn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>12</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>corn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>13</th>\n",
       "      <td>0.310</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>corn</th>\n",
       "      <th>NGK</th>\n",
       "      <th>14</th>\n",
       "      <td>0.370</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>earn</th>\n",
       "      <th>WK</th>\n",
       "      <th>0</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acq</th>\n",
       "      <th>WK</th>\n",
       "      <th>0</th>\n",
       "      <td>0.948</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crude</th>\n",
       "      <th>WK</th>\n",
       "      <th>0</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corn</th>\n",
       "      <th>WK</th>\n",
       "      <th>0</th>\n",
       "      <td>0.770</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           f1_mean  f1_std  precision_mean  precision_std  \\\n",
       "   category ime ljuske k                                                    \n",
       "0  earn     NGK        3   0.885    0.0300  0.885           0.0300          \n",
       "1  earn     NGK        4   0.885    0.0510  0.885           0.0510          \n",
       "2  earn     NGK        5   0.923    0.0280  0.923           0.0280          \n",
       "3  earn     NGK        6   0.930    0.0500  0.930           0.0500          \n",
       "4  earn     NGK        7   0.933    0.0350  0.933           0.0350          \n",
       "5  earn     NGK        8   0.915    0.0410  0.915           0.0410          \n",
       "6  earn     NGK        9   0.918    0.0460  0.918           0.0460          \n",
       "7  earn     NGK        10  0.915    0.0390  0.915           0.0390          \n",
       "8  earn     NGK        11  0.893    0.0550  0.893           0.0550          \n",
       "9  earn     NGK        12  0.908    0.0460  0.908           0.0460          \n",
       "10 earn     NGK        13  0.898    0.0430  0.898           0.0430          \n",
       "11 earn     NGK        14  0.920    0.0520  0.920           0.0520          \n",
       "0  acq      NGK        3   0.952    0.0430  0.952           0.0430          \n",
       "1  acq      NGK        4   0.952    0.0560  0.952           0.0560          \n",
       "2  acq      NGK        5   0.964    0.0380  0.964           0.0380          \n",
       "3  acq      NGK        6   0.948    0.0440  0.948           0.0440          \n",
       "4  acq      NGK        7   0.956    0.0420  0.956           0.0420          \n",
       "5  acq      NGK        8   0.972    0.0260  0.972           0.0260          \n",
       "6  acq      NGK        9   0.948    0.0440  0.948           0.0440          \n",
       "7  acq      NGK        10  0.960    0.0340  0.960           0.0340          \n",
       "8  acq      NGK        11  0.964    0.0330  0.964           0.0330          \n",
       "9  acq      NGK        12  0.924    0.0378  0.924           0.0378          \n",
       "10 acq      NGK        13  0.960    0.0250  0.960           0.0250          \n",
       "11 acq      NGK        14  0.960    0.0360  0.960           0.0360          \n",
       "0  crude    NGK        3   0.847    0.0790  0.847           0.0790          \n",
       "1  crude    NGK        4   0.947    0.0400  0.947           0.0400          \n",
       "2  crude    NGK        5   0.900    0.0445  0.900           0.0450          \n",
       "3  crude    NGK        6   0.887    0.0600  0.887           0.0600          \n",
       "4  crude    NGK        7   0.880    0.0720  0.880           0.0720          \n",
       "5  crude    NGK        8   0.860    0.0758  0.860           0.0758          \n",
       "6  crude    NGK        9   0.880    0.0830  0.880           0.0830          \n",
       "7  crude    NGK        10  0.900    0.0540  0.900           0.0540          \n",
       "8  crude    NGK        11  0.820    0.1030  0.820           0.1030          \n",
       "9  crude    NGK        12  0.840    0.0800  0.840           0.0800          \n",
       "10 crude    NGK        13  0.773    0.1370  0.773           0.1370          \n",
       "11 crude    NGK        14  0.633    0.1340  0.633           0.1340          \n",
       "0  corn     NGK        3   0.830    0.1000  0.830           0.1000          \n",
       "1  corn     NGK        4   0.850    0.0920  0.850           0.0920          \n",
       "2  corn     NGK        5   0.850    0.0920  0.850           0.0920          \n",
       "3  corn     NGK        6   0.840    0.1430  0.840           0.1430          \n",
       "4  corn     NGK        7   0.780    0.1400  0.780           0.1400          \n",
       "5  corn     NGK        8   0.740    0.1560  0.740           0.1560          \n",
       "6  corn     NGK        9   0.640    0.2290  0.640           0.2290          \n",
       "7  corn     NGK        10  0.690    0.1370  0.690           0.1370          \n",
       "8  corn     NGK        11  0.540    0.1740  0.540           0.1700          \n",
       "9  corn     NGK        12  0.500    0.1480  0.500           0.1480          \n",
       "10 corn     NGK        13  0.310    0.1450  0.310           0.1450          \n",
       "11 corn     NGK        14  0.370    0.1270  0.370           0.1270          \n",
       "0  earn     WK         0   0.928    0.0360  0.928           0.0360          \n",
       "   acq      WK         0   0.948    0.0470  0.948           0.0470          \n",
       "   crude    WK         0   0.873    0.0760  0.873           0.0760          \n",
       "   corn     WK         0   0.770    0.1350  0.770           0.1350          \n",
       "\n",
       "                           recall_mean  recall_std  \n",
       "   category ime ljuske k                            \n",
       "0  earn     NGK        3   0.885        0.030       \n",
       "1  earn     NGK        4   0.885        0.051       \n",
       "2  earn     NGK        5   0.923        0.028       \n",
       "3  earn     NGK        6   0.930        0.050       \n",
       "4  earn     NGK        7   0.933        0.035       \n",
       "5  earn     NGK        8   0.915        0.041       \n",
       "6  earn     NGK        9   0.918        0.046       \n",
       "7  earn     NGK        10  0.915        0.039       \n",
       "8  earn     NGK        11  0.893        0.055       \n",
       "9  earn     NGK        12  0.908        0.046       \n",
       "10 earn     NGK        13  0.898        0.043       \n",
       "11 earn     NGK        14  0.920        0.052       \n",
       "0  acq      NGK        3   0.952        0.043       \n",
       "1  acq      NGK        4   0.952        0.056       \n",
       "2  acq      NGK        5   0.964        0.038       \n",
       "3  acq      NGK        6   0.948        0.044       \n",
       "4  acq      NGK        7   0.956        0.042       \n",
       "5  acq      NGK        8   0.972        0.026       \n",
       "6  acq      NGK        9   0.948        0.044       \n",
       "7  acq      NGK        10  0.960        0.034       \n",
       "8  acq      NGK        11  0.964        0.033       \n",
       "9  acq      NGK        12  0.924        0.038       \n",
       "10 acq      NGK        13  0.960        0.025       \n",
       "11 acq      NGK        14  0.960        0.036       \n",
       "0  crude    NGK        3   0.847        0.079       \n",
       "1  crude    NGK        4   0.947        0.040       \n",
       "2  crude    NGK        5   0.900        0.045       \n",
       "3  crude    NGK        6   0.887        0.060       \n",
       "4  crude    NGK        7   0.880        0.072       \n",
       "5  crude    NGK        8   0.860        0.076       \n",
       "6  crude    NGK        9   0.880        0.083       \n",
       "7  crude    NGK        10  0.900        0.054       \n",
       "8  crude    NGK        11  0.820        0.103       \n",
       "9  crude    NGK        12  0.840        0.080       \n",
       "10 crude    NGK        13  0.773        0.137       \n",
       "11 crude    NGK        14  0.633        0.134       \n",
       "0  corn     NGK        3   0.830        0.100       \n",
       "1  corn     NGK        4   0.850        0.092       \n",
       "2  corn     NGK        5   0.850        0.092       \n",
       "3  corn     NGK        6   0.840        0.143       \n",
       "4  corn     NGK        7   0.780        0.140       \n",
       "5  corn     NGK        8   0.740        0.156       \n",
       "6  corn     NGK        9   0.640        0.229       \n",
       "7  corn     NGK        10  0.690        0.137       \n",
       "8  corn     NGK        11  0.540        0.174       \n",
       "9  corn     NGK        12  0.500        0.148       \n",
       "10 corn     NGK        13  0.310        0.145       \n",
       "11 corn     NGK        14  0.370        0.127       \n",
       "0  earn     WK         0   0.928        0.036       \n",
       "   acq      WK         0   0.948        0.047       \n",
       "   crude    WK         0   0.873        0.076       \n",
       "   corn     WK         0   0.770        0.135       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "rezultat = pd.read_csv(\"varying_sequence_length.csv\", index_col=[0, 1, 2, 3])\n",
    "display(rezultat)\n",
    "#pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ee940",
   "metadata": {},
   "source": [
    "### Effectiveness of Varying Weight Decay Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6587c1e8",
   "metadata": {},
   "source": [
    "Sada ispitujemo model za promjenjive vrijednosti lambde. Lambda upravlja \"kažnjavanjem\" ne-susjednih substringova. Što su stringovi \"ne-susjedniji\" u člancima, to su više kažnjeni.\n",
    "\n",
    "Pozivamo iste funkcije kao i za Varying Sequence Length, ali ovaj puta predajemo niz lambdi (weight decay factor) za koje testiramo model.\n",
    "\n",
    "Za svaku vrijednost lambda, eksperiment je proveden 10 puta i onda su dobivene vrijednosti mean i sd. Parametar k je postavljen na 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b39d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rezultat_lista = []\n",
    "def evaluation_for_varying_weight_decay_factors():\n",
    "    #rezultat = []\n",
    "    #varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"lambda\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_weight_decay.to_csv(\"varying_weight_decay.csv\")\n",
    "    \n",
    "    #rezultat = ngk_evaluation(\"earn\")\n",
    "    #varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"lambda\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    #rezultat = ngk_evaluation(\"acq\")\n",
    "    #varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"lambda\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    #rezultat = ngk_evaluation(\"crude\")\n",
    "    #varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"lambda\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    #rezultat = ngk_evaluation(\"corn\")\n",
    "    #varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"lambda\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ssk_evaluation(\"earn\", lambd_range=[0.01, 0.05, 0.3, 0.7])\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"lambda\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ssk_evaluation(\"acq\", lambd_range=[0.01, 0.05, 0.3, 0.7])\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"lambda\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ssk_evaluation(\"crude\", lambd_range=[0.01, 0.05, 0.3, 0.7])\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"lambda\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ssk_evaluation(\"corn\", lambd_range=[0.01, 0.05, 0.3, 0.7])\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"lambda\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = wk_evaluation(\"earn\")\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"lambda\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = wk_evaluation(\"acq\")\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"lambda\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = wk_evaluation(\"crude\")\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"lambda\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = wk_evaluation(\"corn\")\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"lambda\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "\n",
    "evaluation_for_varying_weight_decay_factors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d84076",
   "metadata": {},
   "source": [
    "#### Usporedba rezultata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be1269",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb2ccae",
   "metadata": {},
   "source": [
    "### Effectiveness of Combining Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f392ac7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fd539ee",
   "metadata": {},
   "source": [
    "#### Combining NGK and SSK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cafebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "lambd = 0.5\n",
    "def NGK_SSK_comb_evaluation(category):\n",
    "    rezultat_lista = []\n",
    "    w_ng_list = [1, 0.5, 0.8, 0.9] #[1, 0, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    w_sk_list = [0, 0.5, 0.2, 0.1] #[0, 1, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    for i in len(w_ng_list):\n",
    "        w_ng = w_ng_list[i]\n",
    "        w_sk = w_sk_list[i]\n",
    "        lista_u_ovom_koraku = []\n",
    "        lista_u_ovom_koraku.append(category)\n",
    "        lista_u_ovom_koraku.append(w_ng)\n",
    "        lista_u_ovom_koraku.append(w_sk)\n",
    "        print(w_ng, w_sk)\n",
    "        f1 = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        #for i in range(0, 10):\n",
    "        #treniranje jezgre\n",
    "        [treniranje, y_train] = give_train_test_split(True)\n",
    "        [earn_test, acq_test, crude_test, corn_test, _, _] = give_train_test_split(False)\n",
    "        if(category==\"earn\"):\n",
    "            X_test = earn_test\n",
    "            y_true = np.array(['earn' for i in range(0, len(earn_test))])\n",
    "        elif category == \"acq\":\n",
    "            X_test = acq_test\n",
    "            y_true = np.array(['acq' for i in range(0, len(acq_test))])\n",
    "        elif category == \"crude\":\n",
    "            X_test = crude_test\n",
    "            y_true = np.array(['crude' for i in range(0, len(crude_test))])\n",
    "        else:\n",
    "            X_test = corn_test\n",
    "            y_true = np.array(['corn' for i in range(0, len(corn_test))])\n",
    "            \n",
    "        ssk_kernel = lambda x, y: ssk.ssk(x, y, 5, 0.5)\n",
    "        ssk_train_gram = ssk_compute_train_gram(treniranje, kernel=ssk_kernel)\n",
    "        ssk_test_gram = ssk_compute_test_gram(X_test, treniranje, kernel=ssk_kernel)\n",
    "        ngk_train_gram, ngk_test_gram = ngk.ngkGmats(treniranje, X_test, n=5)\n",
    "            \n",
    "        test_gram = ngk_test_gram*w_ng + ssk_test_gram*w_sk\n",
    "        train_gram = ngk_train_gram*w_ng + ssk_train_gram*w_sk\n",
    "            \n",
    "        clf = SVC(kernel='precomputed')\n",
    "        clf.fit(train_gram, y_train)\n",
    "        y_pred = clf.predict(test_gram)\n",
    "        f1.append(round(f1_score(y_true, y_pred, average='micro')), 3)\n",
    "        precision.append(round(precision_score(y_true, y_pred, average='micro')), 3)\n",
    "        recall.append(round(recall_score(y_true, y_pred, average='micro')), 3)\n",
    "        # kraj for i petlje\n",
    "        \n",
    "        lista_u_ovom_koraku.append(round(np.mean(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(recall), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(recall), 3))\n",
    "        #print(lista_u_ovom_koraku)\n",
    "        rezultat_lista.append(lista_u_ovom_koraku)\n",
    "        \n",
    "    return rezultat_lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4636a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_for_combining_ngk_and_ssk():\n",
    "    rezultat = []\n",
    "    combining_ngk_and_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combining_ngk_and_ssk.to_csv(\"combining_ngk_and_ssk.csv\")\n",
    "    \n",
    "    rezultat = NGK_SSK_comb_evaluation(\"earn\")\n",
    "    combining_ngk_and_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combining_ngk_and_ssk.to_csv(\"combining_ngk_and_ssk.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = NGK_SSK_comb_evaluation(\"acq\")\n",
    "    combining_ngk_and_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combining_ngk_and_ssk.to_csv(\"combining_ngk_and_ssk.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = NGK_SSK_comb_evaluation(\"crude\")\n",
    "    combining_ngk_and_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combining_ngk_and_ssk.to_csv(\"combining_ngk_and_ssk.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = NGK_SSK_comb_evaluation(\"corn\")\n",
    "    combining_ngk_and_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combining_ngk_and_ssk.to_csv(\"combining_ngk_and_ssk.csv\", mode='a', header=False)\n",
    "\n",
    "evaluation_for_combining_ngk_and_ssk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db0429",
   "metadata": {},
   "source": [
    "#### Combining SSK with different lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f5ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSK_lambda_comb_evaluation(category):\n",
    "    rezultat_lista = []\n",
    "    lambda_1_list = [0.05, 0.5, 0.05]\n",
    "    lambda_2_list = [0.0, 0.0, 0.5]\n",
    "    for i in len(lambda_1_list):\n",
    "        lambda1 = lambda_1_list[i]\n",
    "        lambda2 = lambda_2_list[i]\n",
    "        lista_u_ovom_koraku = []\n",
    "        lista_u_ovom_koraku.append(category)\n",
    "        lista_u_ovom_koraku.append(lambda1)\n",
    "        lista_u_ovom_koraku.append(lambda2)\n",
    "        print(lambda1, lambda2)\n",
    "        f1 = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        for i in range(0, 10):\n",
    "            #treniranje jezgre\n",
    "            [treniranje, y_train] = give_train_test_split(True)\n",
    "            [earn_test, acq_test, crude_test, corn_test, _, _] = give_train_test_split(False)\n",
    "            if(category==\"earn\"):\n",
    "                X_test = earn_test\n",
    "                y_true = np.array(['earn' for i in range(0, len(earn_test))])\n",
    "            elif category == \"acq\":\n",
    "                X_test = acq_test\n",
    "                y_true = np.array(['acq' for i in range(0, len(acq_test))])\n",
    "            elif category == \"crude\":\n",
    "                X_test = crude_test\n",
    "                y_true = np.array(['crude' for i in range(0, len(crude_test))])\n",
    "            else:\n",
    "                X_test = corn_test\n",
    "                y_true = np.array(['corn' for i in range(0, len(corn_test))])\n",
    "            \n",
    "            ssk_kernel_1 = lambda x, y: ssk.ssk(x, y, 5, lambda1)\n",
    "            ssk_kernel_2 = lambda x, y: ssk.ssk(x, y, 5, lambda2)\n",
    "            ssk_train_gram_1 = ssk_compute_train_gram(treniranje, kernel=ssk_kernel_1)\n",
    "            ssk_train_gram_2 = ssk_compute_train_gram(treniranje, kernel=ssk_kernel_2)\n",
    "            ssk_test_gram_1 = ssk_compute_test_gram(X_test, treniranje, kernel=ssk_kernel_1)\n",
    "            ssk_test_gram_2 = ssk_compute_test_gram(X_test, treniranje, kernel=ssk_kernel_2)\n",
    "            \n",
    "            train_gram = ssk_train_gram_1 + ssk_train_gram_2\n",
    "            test_gram = ssk_test_gram_1 + ssk_test_gram_2\n",
    "        \n",
    "            clf = SVC(kernel='precomputed')\n",
    "            clf.fit(train_gram, y_train)\n",
    "            y_pred = clf.predict(test_gram)\n",
    "            f1.append(f1_score(y_true, y_pred, average='micro'))\n",
    "            precision.append(precision_score(y_true, y_pred, average='micro'))\n",
    "            recall.append(recall_score(y_true, y_pred, average='micro'))\n",
    "        \n",
    "        lista_u_ovom_koraku.append(round(np.mean(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(recall), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(recall), 3))\n",
    "        #print(lista_u_ovom_koraku)\n",
    "        rezultat_lista.append(lista_u_ovom_koraku)\n",
    "        \n",
    "    return rezultat_lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea8f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_for_combining_lambda_ssk():\n",
    "    rezultat = []\n",
    "    combininig_lambda_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"lambda_1\", \"lambda_2\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_lambda_ssk.to_csv(\"combininig_lambda_ssk.csv\")\n",
    "    \n",
    "    rezultat = SSK_lambda_comb_evaluation(\"earn\")\n",
    "    combininig_lambda_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_lambda_ssk.to_csv(\"combininig_lambda_ssk.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = SSK_lambda_comb_evaluation(\"acq\")\n",
    "    combininig_lambda_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_lambda_ssk.to_csv(\"combininig_lambda_ssk.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = SSK_lambda_comb_evaluation(\"crude\")\n",
    "    combininig_lambda_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_lambda_ssk.to_csv(\"combininig_lambda_ssk.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = SSK_lambda_comb_evaluation(\"corn\")\n",
    "    combininig_lambda_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_lambda_ssk.to_csv(\"combininig_lambda_ssk.csv\", mode='a', header=False)\n",
    "\n",
    "evaluation_for_combining_lambda_ssk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c292615c",
   "metadata": {},
   "source": [
    "## ZANEMARITI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2070e10",
   "metadata": {},
   "source": [
    "Ako treniram modele s punim člancima, onda radi presporo tako da sam odlučila iz svakog članka izdvojiti n = 50 najčešćih riječi i onda po njima uspoređivati članke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b879be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def return_n_most_common_words(row, n):\n",
    "    words_in_row = row['BODY'].split(\" \")\n",
    "    count = Counter()\n",
    "    for word in words_in_row:\n",
    "        if len(word) > 3:\n",
    "            count[word] += 1\n",
    "    lista = np.array([])\n",
    "    for (element, _) in count.most_common(n):\n",
    "        lista = np.append(lista, element)\n",
    "    #row['MOST_COMMON'] = lista\n",
    "    #print(lista)\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5b84076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPICS</th>\n",
       "      <th>BODY</th>\n",
       "      <th>MOST_COMMON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>champion products inc said its board of direct...</td>\n",
       "      <td>[said, board, stock, shares, shareholders, apr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr    cts vs      dlrs     net         vs    ...</td>\n",
       "      <td>[dlrs, assets, deposits, loans, note, availabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>ohio mattress co said its first quarter  endin...</td>\n",
       "      <td>[said, quarter, first, acquisitions, dlrs, sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>oper shr loss two cts vs profit seven cts     ...</td>\n",
       "      <td>[profit, oper, loss, revs, shrs, mths, seven, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr one dlr vs    cts     net      mln vs     ...</td>\n",
       "      <td>[revs, dlrs, nine, mths, billion, reuter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13058</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr loss nine cts vs loss    cts     net loss ...</td>\n",
       "      <td>[loss, dlrs, capitalized, costs, nine, revs, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13059</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr    cts vs    cts     shr diluted    cts vs...</td>\n",
       "      <td>[diluted, shrs, sales, nine, mths, dlrs, reuter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13060</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr    cts vs    cts     net      mln vs      ...</td>\n",
       "      <td>[dlrs, sales, shrs, nine, mths, oper, billion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13103</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>nine months ended august        group shr     ...</td>\n",
       "      <td>[billion, group, nine, months, ended, august, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13104</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>third quarter ended august        group shr   ...</td>\n",
       "      <td>[billion, group, third, quarter, ended, august...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3776 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TOPICS                                               BODY  \\\n",
       "19     'earn'  champion products inc said its board of direct...   \n",
       "21     'earn'  shr    cts vs      dlrs     net         vs    ...   \n",
       "22     'earn'  ohio mattress co said its first quarter  endin...   \n",
       "24     'earn'  oper shr loss two cts vs profit seven cts     ...   \n",
       "25     'earn'  shr one dlr vs    cts     net      mln vs     ...   \n",
       "...       ...                                                ...   \n",
       "13058  'earn'  shr loss nine cts vs loss    cts     net loss ...   \n",
       "13059  'earn'  shr    cts vs    cts     shr diluted    cts vs...   \n",
       "13060  'earn'  shr    cts vs    cts     net      mln vs      ...   \n",
       "13103  'earn'  nine months ended august        group shr     ...   \n",
       "13104  'earn'  third quarter ended august        group shr   ...   \n",
       "\n",
       "                                             MOST_COMMON  \n",
       "19     [said, board, stock, shares, shareholders, apr...  \n",
       "21     [dlrs, assets, deposits, loans, note, availabl...  \n",
       "22     [said, quarter, first, acquisitions, dlrs, sea...  \n",
       "24     [profit, oper, loss, revs, shrs, mths, seven, ...  \n",
       "25             [revs, dlrs, nine, mths, billion, reuter]  \n",
       "...                                                  ...  \n",
       "13058  [loss, dlrs, capitalized, costs, nine, revs, s...  \n",
       "13059   [diluted, shrs, sales, nine, mths, dlrs, reuter]  \n",
       "13060  [dlrs, sales, shrs, nine, mths, oper, billion,...  \n",
       "13103  [billion, group, nine, months, ended, august, ...  \n",
       "13104  [billion, group, third, quarter, ended, august...  \n",
       "\n",
       "[3776 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earn_clanci['MOST_COMMON'] = earn_clanci.apply(lambda row: return_n_most_common_words(row, n=50), axis=1)\n",
    "acq_clanci['MOST_COMMON'] = acq_clanci.apply(lambda row: return_n_most_common_words(row, n=50), axis=1)\n",
    "crude_clanci['MOST_COMMON'] = crude_clanci.apply(lambda row: return_n_most_common_words(row, n=50), axis=1)\n",
    "corn_clanci['MOST_COMMON'] = corn_clanci.apply(lambda row: return_n_most_common_words(row, n=50), axis=1)\n",
    "earn_clanci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90779903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "## MOJ SSK -> radi za onaj mali uvodni primjer\n",
    "import itertools\n",
    "\n",
    "# SSK - string subsequence kernel\n",
    "def is_subsequence(subsequence, word):\n",
    "    iterator = iter(word)\n",
    "    if all(c in iterator for c in subsequence):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ssk_kernel(string1, string2, k=2, lambd=1):\n",
    "    stupci = []\n",
    "    tablica = {}\n",
    "\n",
    "    for word in [string1, string2]:\n",
    "        letters = list(word)\n",
    "        for combination in itertools.combinations(letters, k): # nalazi sve kombinacije slova u letters duljine k\n",
    "            s = ''.join(combination)\n",
    "            if s not in stupci:\n",
    "                stupci.append(s)\n",
    "    \n",
    "    #print(stupci)\n",
    "\n",
    "    for word in [string1, string2]:\n",
    "        tablica[word] = [0 for i in range(len(stupci))]\n",
    "        subsequence_index = 0\n",
    "        for stupac in stupci:\n",
    "            if is_subsequence(stupac, word):\n",
    "                cell_rez = 1\n",
    "                index_slova_rijeci = 0\n",
    "                for index_slova_stupca in range(len(stupac) - 1):\n",
    "                    cell_rez += word.index(stupac[index_slova_stupca+1], word.index(stupac[index_slova_stupca])+1)-word.index(stupac[index_slova_stupca])\n",
    "                tablica[word][subsequence_index] = pow(lambd, cell_rez)\n",
    "                #print(word, tablica[word])\n",
    "                # res += i.index(j[ki+1], i.index(j[ki])+1)-i.index(j[ki])\n",
    "            subsequence_index += 1\n",
    "    red_1 = np.array(tablica[string1])\n",
    "    red_2 = np.array(tablica[string2])\n",
    "    \n",
    "    rez_1 = np.sum(red_1*red_2.T)\n",
    "    rez_2 = np.sum(red_1*red_1.T)\n",
    "    rez_3 = np.sum(red_2*red_2.T)\n",
    "    rez = rez_1/pow(rez_2*rez_3, 0.5)\n",
    "    return rez\n",
    "\n",
    "print(ssk_kernel(\"cat\",\"car\", lambd=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d847ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NGK - n-grams kernel\n",
    "# NGK is a linear kernel that returns a similarity score between documents\n",
    "# that are indexed by n-grams\n",
    "# vrijednost jezgrene funkcije\n",
    "def ngk(string1, string2):\n",
    "    def ngrams(string):\n",
    "        ngrams = set(())\n",
    "        for n in range(1, len(string)+1):\n",
    "            ngrams_helper = zip(*[string[i:] for i in range(n)])\n",
    "            for ngram in ngrams_helper:\n",
    "                ngrams.add(''.join(ngram))\n",
    "        #print(ngrams)\n",
    "        return ngrams\n",
    "    \n",
    "    ngrams_1 = ngrams(string1) # racuna ngrams za prvi dokument\n",
    "    ngrams_2 = ngrams(string2) # racuna ngrams za drugi dokument\n",
    "    \n",
    "    # usporeduje broj jednakih ngrams oba dokumenta\n",
    "    intercept_rez = ngrams_1.intersection(ngrams_2)\n",
    "    num_common = len(intercept_rez)\n",
    "    \n",
    "    rez = num_common/(len(ngrams_1)+len(ngrams_2))\n",
    "    rez = rez/0.5 #skaliranje\n",
    "    return rez\n",
    "\n",
    "def ngk_kernel(X1, X2):\n",
    "    kernel_matrix = np.zeros([len(X1), len(X2)])\n",
    "    for i in range(0, len(X1)):\n",
    "        for j in range(0, len(X2)):\n",
    "            kernel_matrix[i][j] = ngk(X1[i], X1[j])\n",
    "    return kernel_matrix\n",
    "\n",
    "print(ngk_kernel(\"car\",\"cat\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "52ff7c03b8138598d26f7db6d70fd0156ea4d6d9d9b70d008337a8032a894406"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
