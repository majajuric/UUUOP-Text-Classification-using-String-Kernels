{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce26ca48",
   "metadata": {},
   "source": [
    "Sveučilište u Zagrebu<br>\n",
    "Fakultet elektrotehnike i računarstva\n",
    "\n",
    "## Uvod u znanost o podacima\n",
    "\n",
    "# Replikacija rezultata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3015166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.svm import SVC\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "049dcb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swig in c:\\users\\majajuric\\anaconda3\\lib\\site-packages (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install swig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d3da48",
   "metadata": {},
   "source": [
    "Znanstveni rad opisuje novi način razvrstavanja članaka na temelju jezgrenih funkcija. Jezgrene funkcije se koriste jer je članke teško vektorizirati, odnosno pretvoriti u vektor značajki. Znanstveni rad opisuje implementaciju jezgre SSK koja se temelji na uspoređivanju sličnosti članaka na temelju njihovih subsequenca. Subsequenci su uređeni nizovi od *k* slova koji se pojavljuju u članku, ali slova ne moraju biti susjedna. Znanstveni rad uspoređuje SSK jezgru s jezgrama WK i NGK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a97876a",
   "metadata": {},
   "source": [
    "### Priprema podataka\n",
    "U članku piše da su sve riječi u body-jima svih članaka pretvorene u lowercase. Također, uklonjene su sve *stopwords*, a interpunkcijski znakovi zamijenjeni su razmacima. Također, bitni su nam samo stupci TOPICS i BODY tako da ostale možemo izbaciti. Dakle, prvo sam se vratila u prethodnu vježbu i pohranila modificirani dataframe koji sam tamo bila napravila u \"clanci_stripped.csv\" datoteku koju ću dalje koristiti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7351c0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPICS</th>\n",
       "      <th>BODY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['cocoa']</td>\n",
       "      <td>showers continued throughout week bahia cocoa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['grain', 'wheat', 'corn', 'barley', 'oat', 's...</td>\n",
       "      <td>u agriculture department reported farmer owned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['veg-oil', 'linseed', 'lin-oil', 'soy-oil', '...</td>\n",
       "      <td>argentine grain board figures show crop regist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['earn']</td>\n",
       "      <td>champion products inc said board directors app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['acq']</td>\n",
       "      <td>computer terminal systems inc said completed s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              TOPICS  \\\n",
       "0                                          ['cocoa']   \n",
       "1  ['grain', 'wheat', 'corn', 'barley', 'oat', 's...   \n",
       "2  ['veg-oil', 'linseed', 'lin-oil', 'soy-oil', '...   \n",
       "3                                           ['earn']   \n",
       "4                                            ['acq']   \n",
       "\n",
       "                                                BODY  \n",
       "0  showers continued throughout week bahia cocoa ...  \n",
       "1  u agriculture department reported farmer owned...  \n",
       "2  argentine grain board figures show crop regist...  \n",
       "3  champion products inc said board directors app...  \n",
       "4  computer terminal systems inc said completed s...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clanci_stripped = pd.read_csv(\"clanci_stripped.csv\", index_col = 0)\n",
    "clanci_stripped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7176c772",
   "metadata": {},
   "source": [
    "Razdvajamo BODY-je po TOPICS-ima tako da u TOPICS nije lista nego samo jedna vrijednost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "393bdfb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPICS</th>\n",
       "      <th>BODY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'cocoa'</td>\n",
       "      <td>showers continued throughout week bahia cocoa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'grain'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'wheat'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'corn'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'barley'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'oat'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'sorghum'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'veg-oil'</td>\n",
       "      <td>argentine grain board figures show crop regist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'linseed'</td>\n",
       "      <td>argentine grain board figures show crop regist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'lin-oil'</td>\n",
       "      <td>argentine grain board figures show crop regist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TOPICS                                               BODY\n",
       "0     'cocoa'  showers continued throughout week bahia cocoa ...\n",
       "1     'grain'  agriculture department reported farmer owned r...\n",
       "2     'wheat'  agriculture department reported farmer owned r...\n",
       "3      'corn'  agriculture department reported farmer owned r...\n",
       "4    'barley'  agriculture department reported farmer owned r...\n",
       "5       'oat'  agriculture department reported farmer owned r...\n",
       "6   'sorghum'  agriculture department reported farmer owned r...\n",
       "7   'veg-oil'  argentine grain board figures show crop regist...\n",
       "8   'linseed'  argentine grain board figures show crop regist...\n",
       "9   'lin-oil'  argentine grain board figures show crop regist..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clanci_stripped = clanci_stripped.loc[:, [\"TOPICS\", \"BODY\"]]\n",
    "clanci_stripped = clanci_stripped.loc[clanci_stripped.TOPICS.notnull(), :]\n",
    "#print(clanci.head(n=10))\n",
    "mapa = {'TOPICS': [], 'BODY': []}\n",
    "for index, row in clanci_stripped.iterrows():\n",
    "    topics = row.TOPICS.split(\",\")\n",
    "    for topic in topics:\n",
    "        topic = topic.replace('[', \"\")\n",
    "        topic = topic.replace(\"]\", \"\")\n",
    "        if mapa['TOPICS'] is None:\n",
    "            mapa['TOPICS'] = [topic]\n",
    "        else:\n",
    "            mapa['TOPICS'].append(topic)\n",
    "        # izbacujemo non single unicode characters\n",
    "        body = row.BODY\n",
    "        unfiltered_body = \"\"\n",
    "        for word in body.split(\" \"):\n",
    "            if len(word) > 3:\n",
    "                unfiltered_body+=word\n",
    "                unfiltered_body+=\" \"\n",
    "        filtered_body = \"\"\n",
    "        for character in unfiltered_body:\n",
    "            if (character.isalnum()) or (character == ' '):\n",
    "                filtered_body += character\n",
    "        filtered_body = filtered_body.replace('[^a-zA-Z]', \" \")\n",
    "        filtered_body = filtered_body.replace(' [ ]+', ' ')\n",
    "        \n",
    "        if mapa['BODY'] is None:\n",
    "            mapa['BODY'] = [filtered_body]\n",
    "        else:\n",
    "            mapa['BODY'].append(filtered_body)\n",
    "            \n",
    "dataframe = pd.DataFrame(mapa)\n",
    "dataframe.to_csv(\"clanci_split.csv\")\n",
    "dataframe.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bca78e2",
   "metadata": {},
   "source": [
    "## Experimental Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5bf472",
   "metadata": {},
   "source": [
    "Ciljevi eksperimenata su:\n",
    "- proučavati utjecaj promjene parametara k(duljina) i $\\lambda$(težina)\n",
    "- uočiti prednosti kombiniranja različitih jezgri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aaf77b",
   "metadata": {},
   "source": [
    "### Podjela podataka u train i test skup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6d1c8",
   "metadata": {},
   "source": [
    "Eksperimenti su provedeni samo na dijelu Reuters seta. U članku piše da je subset bio veličine 470 dokumenata, od čega je 380 bilo korišteno za treniranje, a 90 za ispitivanje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bad638",
   "metadata": {},
   "source": [
    "U eksperimentu su odabrane kategorij \"earn\", \"acq\", \"crude\" i \"corn\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fca2806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPICS</th>\n",
       "      <th>BODY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>champion products said board directors approve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>dlrs assets deposits loans note available year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>ohio mattress said first quarter ending februa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>oper loss profit seven oper profit profit revs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>revs nine mths dlrs dlrs revs billion reuter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TOPICS                                               BODY\n",
       "19  'earn'  champion products said board directors approve...\n",
       "21  'earn'  dlrs assets deposits loans note available year...\n",
       "22  'earn'  ohio mattress said first quarter ending februa...\n",
       "24  'earn'  oper loss profit seven oper profit profit revs...\n",
       "25  'earn'      revs nine mths dlrs dlrs revs billion reuter "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earn_clanci = dataframe[dataframe.TOPICS.str.contains(\"earn\")]\n",
    "acq_clanci = dataframe[dataframe.TOPICS.str.contains(\"acq\")]\n",
    "crude_clanci = dataframe[dataframe.TOPICS.str.contains(\"crude\")]\n",
    "corn_clanci = dataframe[dataframe.TOPICS.str.contains(\"corn\")]\n",
    "\n",
    "clanci = [earn_clanci, acq_clanci, crude_clanci, corn_clanci]\n",
    "earn_clanci.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1e278",
   "metadata": {},
   "source": [
    "Navedeno je da je broj članaka za pojedinu kategoriju za učenje (ispitivanje) sljedeći:\n",
    "1. earn 152 (40)\n",
    "2. acquisition 114 (25)\n",
    "3. crude 76 (15)\n",
    "4. corn 38 (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f154e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def give_train_test_split(give_train):\n",
    "    [earn_tr, earn_te] = train_test_split(earn_clanci, train_size=152/len(earn_clanci), test_size=40/len(earn_clanci))\n",
    "    [acq_tr, acq_te] = train_test_split(acq_clanci, train_size=114/len(acq_clanci), test_size=25/len(acq_clanci))\n",
    "    [crude_tr, crude_te] = train_test_split(crude_clanci, train_size=76/len(crude_clanci), test_size=15/len(crude_clanci))\n",
    "    [corn_tr, corn_te] = train_test_split(corn_clanci, train_size=38/len(corn_clanci), test_size=10/len(corn_clanci))\n",
    "\n",
    "    y_train = []\n",
    "    y_train.extend(['earn' for i in range(0, len(earn_tr))])\n",
    "    y_train.extend(['acq' for i in range(0, len(acq_tr))])\n",
    "    y_train.extend(['crude' for i in range(0, len(crude_tr))])\n",
    "    y_train.extend(['corn' for i in range(0, len(corn_tr))])\n",
    "    y_train = np.array(y_train)\n",
    "    #print(y_train)\n",
    "\n",
    "    y_test = []\n",
    "    y_test.extend(['earn' for i in range(0, len(earn_te))])\n",
    "    y_test.extend(['acq' for i in range(0, len(acq_te))])\n",
    "    y_test.extend(['crude' for i in range(0, len(crude_te))])\n",
    "    y_test.extend(['corn' for i in range(0, len(corn_te))])\n",
    "    y_test = np.array(y_test)\n",
    "    #print(y_test)\n",
    "\n",
    "    clanci_test = [earn_te, acq_te, crude_te, corn_te]\n",
    "    clanci_test = pd.concat(clanci_test)\n",
    "    clanci_train = [earn_tr, acq_tr, crude_tr, corn_tr]\n",
    "    clanci_train = pd.concat(clanci_train)\n",
    "    #clanci_train #.to_csv(\"clanci_train.csv\")\n",
    "    \n",
    "    earn_test=[]\n",
    "    acq_test=[]\n",
    "    crude_test=[]\n",
    "    corn_test=[]\n",
    "    for index, row in earn_te.iterrows():\n",
    "        earn_test.append(row['BODY'])\n",
    "    for index, row in acq_te.iterrows():\n",
    "        acq_test.append(row['BODY'])\n",
    "    for index, row in crude_te.iterrows():\n",
    "        crude_test.append(row['BODY'])\n",
    "    for index, row in corn_te.iterrows():\n",
    "        corn_test.append(row['BODY'])\n",
    "    \n",
    "    treniranje_parovi = []\n",
    "    treniranje = []\n",
    "    i = 0\n",
    "    for index, row in clanci_train.iterrows():\n",
    "        par = []\n",
    "        par = [row['BODY'], y_train[i]]\n",
    "        treniranje.append(row['BODY'])\n",
    "        treniranje_parovi.append(par)\n",
    "\n",
    "    testiranje = []\n",
    "    for index, row in clanci_test.iterrows():\n",
    "        testiranje.append(row['BODY'])\n",
    "    \n",
    "    if give_train:\n",
    "        return [treniranje, y_train]\n",
    "    else:\n",
    "        return [earn_test, acq_test, crude_test, corn_test, testiranje, y_test]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f5260b",
   "metadata": {},
   "source": [
    "### SSK kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec9ab86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a737b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssk_compute_train_gram(docs, kernel=None):\n",
    "    n = len(docs)\n",
    "    gram = np.ones((n, n))\n",
    "    for x in range(n):\n",
    "        print('{0:.2f}%'.format(x / n))\n",
    "        for y in range(x + 1, n):\n",
    "            gram[x, y] = kernel(docs[x], docs[y])\n",
    "            gram[y, x] = gram[x, y]\n",
    "    return gram  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3670d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssk_compute_test_gram(test, train, kernel=None):\n",
    "    gram = np.zeros((len(test), len(train)))\n",
    "    for x in range(len(test)):\n",
    "        print('{0:.2f}%'.format(x / len(test)))\n",
    "        for y in range(len(train)):\n",
    "            gram[x, y] = kernel(test[x], train[y])\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750371e6",
   "metadata": {},
   "source": [
    "### NGK kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "529ef40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38207551689619024\n",
      "0.24129913647238913\n"
     ]
    }
   ],
   "source": [
    "import ngk\n",
    "\n",
    "doc1, doc2 = 'science is organized knowledge', 'wisdom is organized life'\n",
    "print(ngk.ngk(doc1, doc2))\n",
    "print(ngk.ngk(doc1, doc2, n=7))\n",
    "# isprobati NGK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee86bf1",
   "metadata": {},
   "source": [
    "### Effectiveness of Varying Sequence Length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc05ef",
   "metadata": {},
   "source": [
    "Za svaku vrijednost k, eksperiment je proveden 10 puta i onda su dobivene vrijednosti mean i sd. Lambda je postavljen na 0.5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e654a",
   "metadata": {},
   "source": [
    "Stvorimo listu u koju stavljamo [category, ime ljuske, length, f1_mean, f1_std, precision_mean, precision_std, recall_mean, recall_std]. Od te liste kasnije stvorimo dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f4615",
   "metadata": {},
   "source": [
    "#### Evaluacija SSK jezgre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a9cda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ispisuje tablicu kao sto je u radu\n",
    "def ssk_evaluation(category, k_range=[5], lambd_range=[0.5]):\n",
    "    rezultat_lista = []\n",
    "   \n",
    "    for k in k_range:\n",
    "        for lambd in lambd_range:\n",
    "            print(category, k)\n",
    "            lista_u_ovom_koraku = []\n",
    "            lista_u_ovom_koraku.append(category)\n",
    "            lista_u_ovom_koraku.append(\"SSK\")\n",
    "            f1 = []\n",
    "            precision = []\n",
    "            recall = []\n",
    "            ssk_kernel = lambda x, y: ssk.ssk(x, y, k, lambd)\n",
    "            #for i in range(0, 10):\n",
    "                #treniranje jezgre\n",
    "            [treniranje, y_train] = give_train_test_split(True)\n",
    "            train_gram = ssk_compute_train_gram(treniranje, kernel=ssk_kernel)\n",
    "            print(\"\\t---1---\")\n",
    "            [earn_test, acq_test, crude_test, corn_test, _, _] = give_train_test_split(False)\n",
    "            if(category==\"earn\"):\n",
    "                X_test = earn_test\n",
    "                y_true = np.array(['earn' for i in range(0, len(earn_test))])\n",
    "            elif category == \"acq\":\n",
    "                X_test = acq_test\n",
    "                y_true = np.array(['acq' for i in range(0, len(acq_test))])\n",
    "            elif category == \"crude\":\n",
    "                X_test = crude_test\n",
    "                y_true = np.array(['crude' for i in range(0, len(crude_test))])\n",
    "            else:\n",
    "                X_test = corn_test\n",
    "                y_true = np.array(['corn' for i in range(0, len(corn_test))])\n",
    "\n",
    "            test_gram = ssk_compute_test_gram(X_test, treniranje, kernel=ssk_kernel)\n",
    "            print(\"\\t---2---\")\n",
    "            clf = SVC(kernel='precomputed')\n",
    "            clf.fit(train_gram, y_train)\n",
    "            print(\"\\t---3---\")\n",
    "            # predikcija\n",
    "            y_pred = clf.predict(test_gram)\n",
    "            print(\"\\t---4---\")\n",
    "            f1.append(f1_score(y_true, y_pred, average='micro'))\n",
    "            precision.append(precision_score(y_true, y_pred, average='micro'))\n",
    "            recall.append(recall_score(y_true, y_pred, average='micro'))\n",
    "            \n",
    "        if len(k_range) == 1:\n",
    "            lista_u_ovom_koraku.append(lambd)\n",
    "        else:\n",
    "            lista_u_ovom_koraku.append(k)\n",
    "            \n",
    "        lista_u_ovom_koraku.append(round(np.mean(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(recall), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(recall), 3))\n",
    "        rezultat_lista.append(lista_u_ovom_koraku)\n",
    "    return rezultat_lista\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c014de0d",
   "metadata": {},
   "source": [
    "#### Evaluacija NGK jezgre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76f093fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngk_evaluation(category, k_range=(5, 5)):\n",
    "    rezultat_lista = []\n",
    "   \n",
    "    for k in range(k_range[0], k_range[1]+1):\n",
    "        lista_u_ovom_koraku = []\n",
    "        lista_u_ovom_koraku.append(category)\n",
    "        lista_u_ovom_koraku.append(\"NGK\")\n",
    "        print(k)\n",
    "        f1 = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        for i in range(0, 10):\n",
    "            #treniranje jezgre\n",
    "            [treniranje, y_train] = give_train_test_split(True)\n",
    "            [earn_test, acq_test, crude_test, corn_test, _, _] = give_train_test_split(False)\n",
    "            if(category==\"earn\"):\n",
    "                X_test = earn_test\n",
    "                y_true = np.array(['earn' for i in range(0, len(earn_test))])\n",
    "            elif category == \"acq\":\n",
    "                X_test = acq_test\n",
    "                y_true = np.array(['acq' for i in range(0, len(acq_test))])\n",
    "            elif category == \"crude\":\n",
    "                X_test = crude_test\n",
    "                y_true = np.array(['crude' for i in range(0, len(crude_test))])\n",
    "            else:\n",
    "                X_test = corn_test\n",
    "                y_true = np.array(['corn' for i in range(0, len(corn_test))])\n",
    "\n",
    "            train_gram, test_gram = ngk.ngkGmats(treniranje, X_test, n=k)\n",
    "            clf = SVC(kernel='precomputed')\n",
    "            clf.fit(train_gram, y_train)\n",
    "            y_pred = clf.predict(test_gram)\n",
    "            f1.append(round(f1_score(y_true, y_pred, average='micro'), 3))\n",
    "            precision.append(round(precision_score(y_true, y_pred, average='micro'), 3))\n",
    "            recall.append(round(recall_score(y_true, y_pred, average='micro'), 3))\n",
    "        \n",
    "        if k_range[0]==k_range[1]:\n",
    "            lista_u_ovom_koraku.append(0)\n",
    "        else:\n",
    "            lista_u_ovom_koraku.append(k)\n",
    "        lista_u_ovom_koraku.append(round(np.mean(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(recall), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(recall), 3))\n",
    "        #print(lista_u_ovom_koraku)\n",
    "        rezultat_lista.append(lista_u_ovom_koraku)\n",
    "        \n",
    "    return rezultat_lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21779125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earn 3\n",
      "0.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m     varying_sequence_length \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rezultat, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mime ljuske\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_std\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision_std\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall_std\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     36\u001b[0m     varying_sequence_length\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvarying_sequence_length.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 38\u001b[0m \u001b[43mevaluation_for_varying_sequence_lengths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36mevaluation_for_varying_sequence_lengths\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluation_for_varying_sequence_lengths\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#rezultat = []\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m#varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m#varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     rezultat \u001b[38;5;241m=\u001b[39m \u001b[43mssk_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mearn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     varying_sequence_length \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rezultat, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mime ljuske\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_std\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision_std\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall_std\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     24\u001b[0m     varying_sequence_length\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvarying_sequence_length.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mssk_evaluation\u001b[1;34m(category, k_range, lambd_range)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#for i in range(0, 10):\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#treniranje jezgre\u001b[39;00m\n\u001b[0;32m     17\u001b[0m [treniranje, y_train] \u001b[38;5;241m=\u001b[39m give_train_test_split(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 18\u001b[0m train_gram \u001b[38;5;241m=\u001b[39m \u001b[43mssk_compute_train_gram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtreniranje\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssk_kernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m---1---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m [earn_test, acq_test, crude_test, corn_test, _, _] \u001b[38;5;241m=\u001b[39m give_train_test_split(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mssk_compute_train_gram\u001b[1;34m(docs, kernel)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0:.2f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x \u001b[38;5;241m/\u001b[39m n))\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, n):\n\u001b[1;32m----> 7\u001b[0m         gram[x, y] \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m         gram[y, x] \u001b[38;5;241m=\u001b[39m gram[x, y]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gram\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mssk_evaluation.<locals>.<lambda>\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     12\u001b[0m precision \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m recall \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 14\u001b[0m ssk_kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, y: \u001b[43mssk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#for i in range(0, 10):\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#treniranje jezgre\u001b[39;00m\n\u001b[0;32m     17\u001b[0m [treniranje, y_train] \u001b[38;5;241m=\u001b[39m give_train_test_split(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluation_for_varying_sequence_lengths():\n",
    "    #rezultat = []\n",
    "    #varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_sequence_length.to_csv(\"varying_sequence_length.csv\")\n",
    "    \n",
    "    #rezultat = ngk_evaluation(\"earn\", k_range=(3, 14))\n",
    "    #varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    #rezultat = ngk_evaluation(\"acq\", k_range=(3, 14))\n",
    "    #varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    #rezultat = ngk_evaluation(\"crude\", k_range=(3, 14))\n",
    "    #varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    #rezultat = ngk_evaluation(\"corn\", k_range=(3, 14))\n",
    "    #varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    #varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ssk_evaluation(\"earn\", k_range=[3, 5, 7, 14])\n",
    "    varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ssk_evaluation(\"acq\", k_range=[3, 5, 7, 14])\n",
    "    varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ssk_evaluation(\"crude\", k_range=[3, 5, 7, 14])\n",
    "    varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ssk_evaluation(\"corn\", k_range=[3, 5, 7, 14])\n",
    "    varying_sequence_length = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_sequence_length.to_csv(\"varying_sequence_length.csv\", mode='a', header=False)\n",
    "    \n",
    "evaluation_for_varying_sequence_lengths()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ee940",
   "metadata": {},
   "source": [
    "### Effectiveness of Varying Weight Decay Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6587c1e8",
   "metadata": {},
   "source": [
    "Za svaku vrijednost lambda, eksperiment je proveden 10 puta i onda su dobivene vrijednosti mean i sd. Parametar k je postavljen na 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b39d9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "earn 5\n",
      "0.00%\n",
      "0.00%\n",
      "0.01%\n",
      "0.01%\n",
      "0.01%\n",
      "0.01%\n",
      "0.02%\n",
      "0.02%\n",
      "0.02%\n",
      "0.02%\n",
      "0.03%\n",
      "0.03%\n",
      "0.03%\n",
      "0.03%\n",
      "0.04%\n",
      "0.04%\n",
      "0.04%\n",
      "0.04%\n",
      "0.05%\n",
      "0.05%\n",
      "0.05%\n",
      "0.06%\n",
      "0.06%\n",
      "0.06%\n",
      "0.06%\n",
      "0.07%\n",
      "0.07%\n",
      "0.07%\n",
      "0.07%\n",
      "0.08%\n"
     ]
    }
   ],
   "source": [
    "rezultat_lista = []\n",
    "def evaluation_for_varying_weight_decay_factors():\n",
    "    rezultat = []\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"lambda\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\")\n",
    "    \n",
    "    rezultat = ngk_evaluation(\"earn\")\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ngk_evaluation(\"acq\")\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ngk_evaluation(\"crude\")\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ngk_evaluation(\"corn\")\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ssk_evaluation(\"earn\", lambd_range=[0.01, 0.03, 0.05, 0.07, 0.09, 0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ssk_evaluation(\"acq\", lambd_range=[0.01, 0.03, 0.05, 0.07, 0.09, 0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ssk_evaluation(\"crude\", lambd_range=[0.01, 0.03, 0.05, 0.07, 0.09, 0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = ssk_evaluation(\"corn\", lambd_range=[0.01, 0.03, 0.05, 0.07, 0.09, 0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "    varying_weight_decay = pd.DataFrame(rezultat, columns=[\"category\", \"ime ljuske\", \"k\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    varying_weight_decay.to_csv(\"varying_weight_decay.csv\", mode='a', header=False)\n",
    "\n",
    "evaluation_for_varying_weight_decay_factors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb2ccae",
   "metadata": {},
   "source": [
    "### Effectiveness of Combining Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd539ee",
   "metadata": {},
   "source": [
    "#### Combining NGK and SSK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cafebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "lambd = 0.5\n",
    "def NGK_SSK_comb_evaluation(category):\n",
    "    rezultat_lista = []\n",
    "    w_ng_list = [1, 0.5, 0.8, 0.9] #[1, 0, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    w_sk_list = [0, 0.5, 0.2, 0.1] #[0, 1, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    for i in len(w_ng_list):\n",
    "        w_ng = w_ng_list[i]\n",
    "        w_sk = w_sk_list[i]\n",
    "        lista_u_ovom_koraku = []\n",
    "        lista_u_ovom_koraku.append(category)\n",
    "        lista_u_ovom_koraku.append(w_ng)\n",
    "        lista_u_ovom_koraku.append(w_sk)\n",
    "        print(w_ng, w_sk)\n",
    "        f1 = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        #for i in range(0, 10):\n",
    "        #treniranje jezgre\n",
    "        [treniranje, y_train] = give_train_test_split(True)\n",
    "        [earn_test, acq_test, crude_test, corn_test, _, _] = give_train_test_split(False)\n",
    "        if(category==\"earn\"):\n",
    "            X_test = earn_test\n",
    "            y_true = np.array(['earn' for i in range(0, len(earn_test))])\n",
    "        elif category == \"acq\":\n",
    "            X_test = acq_test\n",
    "            y_true = np.array(['acq' for i in range(0, len(acq_test))])\n",
    "        elif category == \"crude\":\n",
    "            X_test = crude_test\n",
    "            y_true = np.array(['crude' for i in range(0, len(crude_test))])\n",
    "        else:\n",
    "            X_test = corn_test\n",
    "            y_true = np.array(['corn' for i in range(0, len(corn_test))])\n",
    "            \n",
    "        ssk_kernel = lambda x, y: ssk.ssk(x, y, 5, 0.5)\n",
    "        ssk_train_gram = ssk_compute_train_gram(treniranje, kernel=ssk_kernel)\n",
    "        ssk_test_gram = ssk_compute_test_gram(X_test, treniranje, kernel=ssk_kernel)\n",
    "        ngk_train_gram, ngk_test_gram = ngk.ngkGmats(treniranje, X_test, n=5)\n",
    "            \n",
    "        test_gram = ngk_test_gram*w_ng + ssk_test_gram*w_sk\n",
    "        train_gram = ngk_train_gram*w_ng + ssk_train_gram*w_sk\n",
    "            \n",
    "        clf = SVC(kernel='precomputed')\n",
    "        clf.fit(train_gram, y_train)\n",
    "        y_pred = clf.predict(test_gram)\n",
    "        f1.append(round(f1_score(y_true, y_pred, average='micro')), 3)\n",
    "        precision.append(round(precision_score(y_true, y_pred, average='micro')), 3)\n",
    "        recall.append(round(recall_score(y_true, y_pred, average='micro')), 3)\n",
    "        # kraj for i petlje\n",
    "        \n",
    "        lista_u_ovom_koraku.append(round(np.mean(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(recall), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(recall), 3))\n",
    "        #print(lista_u_ovom_koraku)\n",
    "        rezultat_lista.append(lista_u_ovom_koraku)\n",
    "        \n",
    "    return rezultat_lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4636a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_for_combining_ngk_and_ssk():\n",
    "    rezultat = []\n",
    "    combininig_ngk_and_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_ngk_and_ssk.to_csv(\"combininig_ngk_and_ssk.csv\")\n",
    "    \n",
    "    rezultat = NGK_SSK_comb_evaluation(\"earn\")\n",
    "    combininig_ngk_and_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_ngk_and_ssk.to_csv(\"combininig_ngk_and_ssk.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = NGK_SSK_comb_evaluation(\"acq\")\n",
    "    combininig_ngk_and_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_ngk_and_ssk.to_csv(\"combininig_ngk_and_ssk.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = NGK_SSK_comb_evaluation(\"crude\")\n",
    "    combininig_ngk_and_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_ngk_and_ssk.to_csv(\"combininig_ngk_and_ssk.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = NGK_SSK_comb_evaluation(\"corn\")\n",
    "    combininig_ngk_and_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_ngk_and_ssk.to_csv(\"combininig_ngk_and_ssk.csv\", mode='a', header=False)\n",
    "\n",
    "evaluation_for_combining_ngk_and_ssk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db0429",
   "metadata": {},
   "source": [
    "#### Combining SSK with different lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f5ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSK_lambda_comb_evaluation(category):\n",
    "    rezultat_lista = []\n",
    "    lambda_1_list = [0.05, 0.5, 0.05]\n",
    "    lambda_2_list = [0.0, 0.0, 0.5]\n",
    "    for i in len(lambda_1_list):\n",
    "        lambda1 = lambda_1_list[i]\n",
    "        lambda2 = lambda_2_list[i]\n",
    "        lista_u_ovom_koraku = []\n",
    "        lista_u_ovom_koraku.append(category)\n",
    "        lista_u_ovom_koraku.append(lambda1)\n",
    "        lista_u_ovom_koraku.append(lambda2)\n",
    "        print(lambda1, lambda2)\n",
    "        f1 = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        for i in range(0, 10):\n",
    "            #treniranje jezgre\n",
    "            [treniranje, y_train] = give_train_test_split(True)\n",
    "            [earn_test, acq_test, crude_test, corn_test, _, _] = give_train_test_split(False)\n",
    "            if(category==\"earn\"):\n",
    "                X_test = earn_test\n",
    "                y_true = np.array(['earn' for i in range(0, len(earn_test))])\n",
    "            elif category == \"acq\":\n",
    "                X_test = acq_test\n",
    "                y_true = np.array(['acq' for i in range(0, len(acq_test))])\n",
    "            elif category == \"crude\":\n",
    "                X_test = crude_test\n",
    "                y_true = np.array(['crude' for i in range(0, len(crude_test))])\n",
    "            else:\n",
    "                X_test = corn_test\n",
    "                y_true = np.array(['corn' for i in range(0, len(corn_test))])\n",
    "            \n",
    "            ssk_kernel_1 = lambda x, y: ssk.ssk(x, y, 5, lambda1)\n",
    "            ssk_kernel_2 = lambda x, y: ssk.ssk(x, y, 5, lambda2)\n",
    "            ssk_train_gram_1 = ssk_compute_train_gram(treniranje, kernel=ssk_kernel_1)\n",
    "            ssk_train_gram_2 = ssk_compute_train_gram(treniranje, kernel=ssk_kernel_2)\n",
    "            ssk_test_gram_1 = ssk_compute_test_gram(X_test, treniranje, kernel=ssk_kernel_1)\n",
    "            ssk_test_gram_2 = ssk_compute_test_gram(X_test, treniranje, kernel=ssk_kernel_2)\n",
    "            \n",
    "            train_gram = ssk_train_gram_1 + ssk_train_gram_2\n",
    "            test_gram = ssk_test_gram_1 + ssk_test_gram_2\n",
    "        \n",
    "            clf = SVC(kernel='precomputed')\n",
    "            clf.fit(train_gram, y_train)\n",
    "            y_pred = clf.predict(test_gram)\n",
    "            f1.append(f1_score(y_true, y_pred, average='micro'))\n",
    "            precision.append(precision_score(y_true, y_pred, average='micro'))\n",
    "            recall.append(recall_score(y_true, y_pred, average='micro'))\n",
    "        \n",
    "        lista_u_ovom_koraku.append(round(np.mean(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(f1), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(precision), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.mean(recall), 3))\n",
    "        lista_u_ovom_koraku.append(round(np.std(recall), 3))\n",
    "        #print(lista_u_ovom_koraku)\n",
    "        rezultat_lista.append(lista_u_ovom_koraku)\n",
    "        \n",
    "    return rezultat_lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea8f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_for_combining_lambda_ssk():\n",
    "    rezultat = []\n",
    "    combininig_lambda_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"lambda_1\", \"lambda_2\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_lambda_ssk.to_csv(\"combininig_lambda_ssk.csv\")\n",
    "    \n",
    "    rezultat = SSK_lambda_comb_evaluation(\"earn\")\n",
    "    combininig_lambda_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_lambda_ssk.to_csv(\"combininig_lambda_ssk.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = SSK_lambda_comb_evaluation(\"acq\")\n",
    "    combininig_lambda_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_lambda_ssk.to_csv(\"combininig_lambda_ssk.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = SSK_lambda_comb_evaluation(\"crude\")\n",
    "    combininig_lambda_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_lambda_ssk.to_csv(\"combininig_lambda_ssk.csv\", mode='a', header=False)\n",
    "    \n",
    "    rezultat = SSK_lambda_comb_evaluation(\"corn\")\n",
    "    combininig_lambda_ssk = pd.DataFrame(rezultat, columns=[\"category\", \"w_ng\", \"w_sk\", \"f1_mean\", \"f1_std\", \"precision_mean\", \"precision_std\", \"recall_mean\", \"recall_std\"])\n",
    "    combininig_lambda_ssk.to_csv(\"combininig_lambda_ssk.csv\", mode='a', header=False)\n",
    "\n",
    "evaluation_for_combining_lambda_ssk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c292615c",
   "metadata": {},
   "source": [
    "## ZANEMARITI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2070e10",
   "metadata": {},
   "source": [
    "Ako treniram modele s punim člancima, onda radi presporo tako da sam odlučila iz svakog članka izdvojiti n = 50 najčešćih riječi i onda po njima uspoređivati članke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b879be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def return_n_most_common_words(row, n):\n",
    "    words_in_row = row['BODY'].split(\" \")\n",
    "    count = Counter()\n",
    "    for word in words_in_row:\n",
    "        if len(word) > 3:\n",
    "            count[word] += 1\n",
    "    lista = np.array([])\n",
    "    for (element, _) in count.most_common(n):\n",
    "        lista = np.append(lista, element)\n",
    "    #row['MOST_COMMON'] = lista\n",
    "    #print(lista)\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5b84076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPICS</th>\n",
       "      <th>BODY</th>\n",
       "      <th>MOST_COMMON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>champion products inc said its board of direct...</td>\n",
       "      <td>[said, board, stock, shares, shareholders, apr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr    cts vs      dlrs     net         vs    ...</td>\n",
       "      <td>[dlrs, assets, deposits, loans, note, availabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>ohio mattress co said its first quarter  endin...</td>\n",
       "      <td>[said, quarter, first, acquisitions, dlrs, sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>oper shr loss two cts vs profit seven cts     ...</td>\n",
       "      <td>[profit, oper, loss, revs, shrs, mths, seven, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr one dlr vs    cts     net      mln vs     ...</td>\n",
       "      <td>[revs, dlrs, nine, mths, billion, reuter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13058</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr loss nine cts vs loss    cts     net loss ...</td>\n",
       "      <td>[loss, dlrs, capitalized, costs, nine, revs, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13059</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr    cts vs    cts     shr diluted    cts vs...</td>\n",
       "      <td>[diluted, shrs, sales, nine, mths, dlrs, reuter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13060</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr    cts vs    cts     net      mln vs      ...</td>\n",
       "      <td>[dlrs, sales, shrs, nine, mths, oper, billion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13103</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>nine months ended august        group shr     ...</td>\n",
       "      <td>[billion, group, nine, months, ended, august, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13104</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>third quarter ended august        group shr   ...</td>\n",
       "      <td>[billion, group, third, quarter, ended, august...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3776 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TOPICS                                               BODY  \\\n",
       "19     'earn'  champion products inc said its board of direct...   \n",
       "21     'earn'  shr    cts vs      dlrs     net         vs    ...   \n",
       "22     'earn'  ohio mattress co said its first quarter  endin...   \n",
       "24     'earn'  oper shr loss two cts vs profit seven cts     ...   \n",
       "25     'earn'  shr one dlr vs    cts     net      mln vs     ...   \n",
       "...       ...                                                ...   \n",
       "13058  'earn'  shr loss nine cts vs loss    cts     net loss ...   \n",
       "13059  'earn'  shr    cts vs    cts     shr diluted    cts vs...   \n",
       "13060  'earn'  shr    cts vs    cts     net      mln vs      ...   \n",
       "13103  'earn'  nine months ended august        group shr     ...   \n",
       "13104  'earn'  third quarter ended august        group shr   ...   \n",
       "\n",
       "                                             MOST_COMMON  \n",
       "19     [said, board, stock, shares, shareholders, apr...  \n",
       "21     [dlrs, assets, deposits, loans, note, availabl...  \n",
       "22     [said, quarter, first, acquisitions, dlrs, sea...  \n",
       "24     [profit, oper, loss, revs, shrs, mths, seven, ...  \n",
       "25             [revs, dlrs, nine, mths, billion, reuter]  \n",
       "...                                                  ...  \n",
       "13058  [loss, dlrs, capitalized, costs, nine, revs, s...  \n",
       "13059   [diluted, shrs, sales, nine, mths, dlrs, reuter]  \n",
       "13060  [dlrs, sales, shrs, nine, mths, oper, billion,...  \n",
       "13103  [billion, group, nine, months, ended, august, ...  \n",
       "13104  [billion, group, third, quarter, ended, august...  \n",
       "\n",
       "[3776 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earn_clanci['MOST_COMMON'] = earn_clanci.apply(lambda row: return_n_most_common_words(row, n=50), axis=1)\n",
    "acq_clanci['MOST_COMMON'] = acq_clanci.apply(lambda row: return_n_most_common_words(row, n=50), axis=1)\n",
    "crude_clanci['MOST_COMMON'] = crude_clanci.apply(lambda row: return_n_most_common_words(row, n=50), axis=1)\n",
    "corn_clanci['MOST_COMMON'] = corn_clanci.apply(lambda row: return_n_most_common_words(row, n=50), axis=1)\n",
    "earn_clanci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90779903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "## MOJ SSK -> radi za onaj mali uvodni primjer\n",
    "import itertools\n",
    "\n",
    "# SSK - string subsequence kernel\n",
    "def is_subsequence(subsequence, word):\n",
    "    iterator = iter(word)\n",
    "    if all(c in iterator for c in subsequence):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ssk_kernel(string1, string2, k=2, lambd=1):\n",
    "    stupci = []\n",
    "    tablica = {}\n",
    "\n",
    "    for word in [string1, string2]:\n",
    "        letters = list(word)\n",
    "        for combination in itertools.combinations(letters, k): # nalazi sve kombinacije slova u letters duljine k\n",
    "            s = ''.join(combination)\n",
    "            if s not in stupci:\n",
    "                stupci.append(s)\n",
    "    \n",
    "    #print(stupci)\n",
    "\n",
    "    for word in [string1, string2]:\n",
    "        tablica[word] = [0 for i in range(len(stupci))]\n",
    "        subsequence_index = 0\n",
    "        for stupac in stupci:\n",
    "            if is_subsequence(stupac, word):\n",
    "                cell_rez = 1\n",
    "                index_slova_rijeci = 0\n",
    "                for index_slova_stupca in range(len(stupac) - 1):\n",
    "                    cell_rez += word.index(stupac[index_slova_stupca+1], word.index(stupac[index_slova_stupca])+1)-word.index(stupac[index_slova_stupca])\n",
    "                tablica[word][subsequence_index] = pow(lambd, cell_rez)\n",
    "                #print(word, tablica[word])\n",
    "                # res += i.index(j[ki+1], i.index(j[ki])+1)-i.index(j[ki])\n",
    "            subsequence_index += 1\n",
    "    red_1 = np.array(tablica[string1])\n",
    "    red_2 = np.array(tablica[string2])\n",
    "    \n",
    "    rez_1 = np.sum(red_1*red_2.T)\n",
    "    rez_2 = np.sum(red_1*red_1.T)\n",
    "    rez_3 = np.sum(red_2*red_2.T)\n",
    "    rez = rez_1/pow(rez_2*rez_3, 0.5)\n",
    "    return rez\n",
    "\n",
    "print(ssk_kernel(\"cat\",\"car\", lambd=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d847ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NGK - n-grams kernel\n",
    "# NGK is a linear kernel that returns a similarity score between documents\n",
    "# that are indexed by n-grams\n",
    "# vrijednost jezgrene funkcije\n",
    "def ngk(string1, string2):\n",
    "    def ngrams(string):\n",
    "        ngrams = set(())\n",
    "        for n in range(1, len(string)+1):\n",
    "            ngrams_helper = zip(*[string[i:] for i in range(n)])\n",
    "            for ngram in ngrams_helper:\n",
    "                ngrams.add(''.join(ngram))\n",
    "        #print(ngrams)\n",
    "        return ngrams\n",
    "    \n",
    "    ngrams_1 = ngrams(string1) # racuna ngrams za prvi dokument\n",
    "    ngrams_2 = ngrams(string2) # racuna ngrams za drugi dokument\n",
    "    \n",
    "    # usporeduje broj jednakih ngrams oba dokumenta\n",
    "    intercept_rez = ngrams_1.intersection(ngrams_2)\n",
    "    num_common = len(intercept_rez)\n",
    "    \n",
    "    rez = num_common/(len(ngrams_1)+len(ngrams_2))\n",
    "    rez = rez/0.5 #skaliranje\n",
    "    return rez\n",
    "\n",
    "def ngk_kernel(X1, X2):\n",
    "    kernel_matrix = np.zeros([len(X1), len(X2)])\n",
    "    for i in range(0, len(X1)):\n",
    "        for j in range(0, len(X2)):\n",
    "            kernel_matrix[i][j] = ngk(X1[i], X1[j])\n",
    "    return kernel_matrix\n",
    "\n",
    "print(ngk_kernel(\"car\",\"cat\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "52ff7c03b8138598d26f7db6d70fd0156ea4d6d9d9b70d008337a8032a894406"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
