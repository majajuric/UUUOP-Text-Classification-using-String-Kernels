{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce26ca48",
   "metadata": {},
   "source": [
    "Sveučilište u Zagrebu<br>\n",
    "Fakultet elektrotehnike i računarstva\n",
    "\n",
    "## Uvod u znanost o podacima\n",
    "\n",
    "# Replikacija rezultata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3015166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a97876a",
   "metadata": {},
   "source": [
    "### Priprema podataka\n",
    "U članku piše da su sve riječi u body-jima svih članaka pretvorene u lowercase. Također, uklonjene su sve *stopwords*, a interpunkcijski znakovi zamijenjeni su razmacima. Dakle, prvo sam se vratila u prethodnu vježbu i pohranila modificirani dataframe koji sam tamo bila napravila u \"clanci_stripped.csv\" datoteku koju ću dalje koristiti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7351c0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPICS</th>\n",
       "      <th>PLACES</th>\n",
       "      <th>PEOPLE</th>\n",
       "      <th>ORGS</th>\n",
       "      <th>EXCHANGES</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>DATELINE</th>\n",
       "      <th>TOPICS_ENUM</th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>BODY</th>\n",
       "      <th>TEXT TYPE</th>\n",
       "      <th>LEWISSPLIT</th>\n",
       "      <th>CGISPLIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['cocoa']</td>\n",
       "      <td>['el-salvador', 'usa', 'uruguay']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BAHIA COCOA REVIEW</td>\n",
       "      <td>SALVADOR, Feb 26 -</td>\n",
       "      <td>2</td>\n",
       "      <td>reut2-000.sgm</td>\n",
       "      <td>26-FEB-1987 15:01:01.79</td>\n",
       "      <td>showers continued throughout the week in the b...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>['usa']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STANDARD OIL &amp;lt;SRD&gt; TO FORM FINANCIAL UNIT</td>\n",
       "      <td>CLEVELAND, Feb 26 -</td>\n",
       "      <td>1</td>\n",
       "      <td>reut2-000.sgm</td>\n",
       "      <td>26-FEB-1987 15:02:20.00</td>\n",
       "      <td>standard oil co and bp north america inc said ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>['usa']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEXAS COMMERCE BANCSHARES &amp;lt;TCB&gt; FILES PLAN</td>\n",
       "      <td>HOUSTON, Feb 26 -</td>\n",
       "      <td>1</td>\n",
       "      <td>reut2-000.sgm</td>\n",
       "      <td>26-FEB-1987 15:03:27.51</td>\n",
       "      <td>texas commerce bancshares incs texas commerce ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>['usa', 'brazil']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TALKING POINT/BANKAMERICA &amp;lt;BAC&gt; EQUITY OFFER</td>\n",
       "      <td>LOS ANGELES, Feb 26 -</td>\n",
       "      <td>1</td>\n",
       "      <td>reut2-000.sgm</td>\n",
       "      <td>26-FEB-1987 15:07:13.72</td>\n",
       "      <td>bankamerica corp is not under pressure to act ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['grain', 'wheat', 'corn', 'barley', 'oat', 's...</td>\n",
       "      <td>['usa']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NATIONAL AVERAGE PRICES FOR FARMER-OWNED RESERVE</td>\n",
       "      <td>WASHINGTON, Feb 26 -</td>\n",
       "      <td>2</td>\n",
       "      <td>reut2-000.sgm</td>\n",
       "      <td>26-FEB-1987 15:10:44.60</td>\n",
       "      <td>the u s  agriculture department reported the f...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              TOPICS  \\\n",
       "0                                          ['cocoa']   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  ['grain', 'wheat', 'corn', 'barley', 'oat', 's...   \n",
       "\n",
       "                              PLACES PEOPLE ORGS EXCHANGES  \\\n",
       "0  ['el-salvador', 'usa', 'uruguay']    NaN  NaN       NaN   \n",
       "1                            ['usa']    NaN  NaN       NaN   \n",
       "2                            ['usa']    NaN  NaN       NaN   \n",
       "3                  ['usa', 'brazil']    NaN  NaN       NaN   \n",
       "4                            ['usa']    NaN  NaN       NaN   \n",
       "\n",
       "                                              TITLE  \\\n",
       "0                                BAHIA COCOA REVIEW   \n",
       "1      STANDARD OIL &lt;SRD> TO FORM FINANCIAL UNIT   \n",
       "2     TEXAS COMMERCE BANCSHARES &lt;TCB> FILES PLAN   \n",
       "3   TALKING POINT/BANKAMERICA &lt;BAC> EQUITY OFFER   \n",
       "4  NATIONAL AVERAGE PRICES FOR FARMER-OWNED RESERVE   \n",
       "\n",
       "                     DATELINE  TOPICS_ENUM       FILENAME  \\\n",
       "0         SALVADOR, Feb 26 -             2  reut2-000.sgm   \n",
       "1        CLEVELAND, Feb 26 -             1  reut2-000.sgm   \n",
       "2          HOUSTON, Feb 26 -             1  reut2-000.sgm   \n",
       "3      LOS ANGELES, Feb 26 -             1  reut2-000.sgm   \n",
       "4       WASHINGTON, Feb 26 -             2  reut2-000.sgm   \n",
       "\n",
       "                      DATE                                               BODY  \\\n",
       "0  26-FEB-1987 15:01:01.79  showers continued throughout the week in the b...   \n",
       "1  26-FEB-1987 15:02:20.00  standard oil co and bp north america inc said ...   \n",
       "2  26-FEB-1987 15:03:27.51  texas commerce bancshares incs texas commerce ...   \n",
       "3  26-FEB-1987 15:07:13.72  bankamerica corp is not under pressure to act ...   \n",
       "4  26-FEB-1987 15:10:44.60  the u s  agriculture department reported the f...   \n",
       "\n",
       "   TEXT TYPE  LEWISSPLIT  CGISPLIT  \n",
       "0          0           2         1  \n",
       "1          0           2         1  \n",
       "2          0           2         1  \n",
       "3          0           2         1  \n",
       "4          0           2         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clanci_stripped = pd.read_csv(\"clanci_stripped.csv\", index_col = 0)\n",
    "clanci_stripped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfa229d",
   "metadata": {},
   "source": [
    "Bitni su nam samo stupci TOPICS i BODY tako da ostale možemo izbaciti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "393bdfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPICS</th>\n",
       "      <th>BODY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'cocoa'</td>\n",
       "      <td>showers continued throughout week bahia cocoa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'grain'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'wheat'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'corn'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'barley'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'oat'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'sorghum'</td>\n",
       "      <td>agriculture department reported farmer owned r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'veg-oil'</td>\n",
       "      <td>argentine grain board figures show crop regist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'linseed'</td>\n",
       "      <td>argentine grain board figures show crop regist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'lin-oil'</td>\n",
       "      <td>argentine grain board figures show crop regist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TOPICS                                               BODY\n",
       "0     'cocoa'  showers continued throughout week bahia cocoa ...\n",
       "1     'grain'  agriculture department reported farmer owned r...\n",
       "2     'wheat'  agriculture department reported farmer owned r...\n",
       "3      'corn'  agriculture department reported farmer owned r...\n",
       "4    'barley'  agriculture department reported farmer owned r...\n",
       "5       'oat'  agriculture department reported farmer owned r...\n",
       "6   'sorghum'  agriculture department reported farmer owned r...\n",
       "7   'veg-oil'  argentine grain board figures show crop regist...\n",
       "8   'linseed'  argentine grain board figures show crop regist...\n",
       "9   'lin-oil'  argentine grain board figures show crop regist..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clanci_stripped = clanci_stripped.loc[:, [\"TOPICS\", \"BODY\"]]\n",
    "clanci_stripped = clanci_stripped.loc[clanci_stripped.TOPICS.notnull(), :]\n",
    "#print(clanci.head(n=10))\n",
    "mapa = {'TOPICS': [], 'BODY': []}\n",
    "for index, row in clanci_stripped.iterrows():\n",
    "    topics = row.TOPICS.split(\",\")\n",
    "    for topic in topics:\n",
    "        topic = topic.replace('[', \"\")\n",
    "        topic = topic.replace(\"]\", \"\")\n",
    "        if mapa['TOPICS'] is None:\n",
    "            mapa['TOPICS'] = [topic]\n",
    "        else:\n",
    "            mapa['TOPICS'].append(topic)\n",
    "        # izbacujemo non single unicode characters\n",
    "        body = row.BODY\n",
    "        unfiltered_body = \"\"\n",
    "        for word in body.split(\" \"):\n",
    "            if len(word) > 3:\n",
    "                unfiltered_body+=word\n",
    "                unfiltered_body+=\" \"\n",
    "        filtered_body = \"\"\n",
    "        for character in unfiltered_body:\n",
    "            if (character.isalnum()) or (character == ' '):\n",
    "                filtered_body += character\n",
    "        filtered_body = filtered_body.replace(' [ ]+', ' ')\n",
    "        \n",
    "        if mapa['BODY'] is None:\n",
    "            mapa['BODY'] = [filtered_body]\n",
    "        else:\n",
    "            mapa['BODY'].append(filtered_body)\n",
    "            \n",
    "dataframe = pd.DataFrame(mapa)\n",
    "dataframe.to_csv(\"clanci_reduced.csv\")\n",
    "dataframe.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bec4ecd",
   "metadata": {},
   "source": [
    "## Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f561ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyximport; pyximport.install(setup_args={\"script_args\":[\"--compiler=mingw32\"],\n",
    "                              \"include_dirs\":np.get_include()},\n",
    "                  reload_support=True)\n",
    "from string_kernel import ssk, string_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b0039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ssk(\"science is organized knowledge\", \"wisdom is organized life\", n=4, lbda=1, accum=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16cc1ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WK - standard word kernel\n",
    "# WK is a linear kernel that measures the similarity between documents\n",
    "# that are indexed by words with tfidf weighting sheme\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# tf - term frequency\n",
    "# df - document frequency\n",
    "# n - total number of document\n",
    "\n",
    "def wk_kernel(X, Y):\n",
    "    n = len(X)\n",
    "    kernel_matrix = np.zeros([len(X), len(X)])\n",
    "    for i in range(0, len(X)):\n",
    "        for j in range(0, len(X)):\n",
    "            kernel_matrix[i][j] = wk(X[i], X[j])\n",
    "    return kernel_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd0f9d51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# NGK - n-grams kernel\n",
    "# NGK is a linear kernel that returns a similarity score between documents\n",
    "# that are indexed by n-grams\n",
    "# vrijednost jezgrene funkcije\n",
    "def ngk(string1, string2):\n",
    "    def ngrams(string):\n",
    "        ngrams = set(())\n",
    "        for n in range(1, len(string)+1):\n",
    "            ngrams_helper = zip(*[string[i:] for i in range(n)])\n",
    "            for ngram in ngrams_helper:\n",
    "                ngrams.add(''.join(ngram))\n",
    "        #print(ngrams)\n",
    "        return ngrams\n",
    "    \n",
    "    ngrams_1 = ngrams(string1) # racuna ngrams za prvi dokument\n",
    "    ngrams_2 = ngrams(string2) # racuna ngrams za drugi dokument\n",
    "    \n",
    "    # usporeduje broj jednakih ngrams oba dokumenta\n",
    "    intercept_rez = ngrams_1.intersection(ngrams_2)\n",
    "    num_common = len(intercept_rez)\n",
    "    \n",
    "    rez = num_common/(len(ngrams_1)+len(ngrams_2))\n",
    "    rez = rez/0.5 #skaliranje\n",
    "    return rez\n",
    "\n",
    "def ngk_kernel(X1, X2):\n",
    "    kernel_matrix = np.zeros([len(X1), len(X2)])\n",
    "    for i in range(0, len(X1)):\n",
    "        for j in range(0, len(X2)):\n",
    "            kernel_matrix[i][j] = ngk(X1[i], X1[j])\n",
    "    return kernel_matrix\n",
    "\n",
    "print(ngk_kernel(\"car\",\"cat\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bca78e2",
   "metadata": {},
   "source": [
    "## Experimental Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5bf472",
   "metadata": {},
   "source": [
    "Ciljevi eksperimenata su:\n",
    "- proučavati utjecaj promjene parametara k(duljina) i $\\lambda$(težina)\n",
    "- uočiti prednosti kombiniranja različitih jezgri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6d1c8",
   "metadata": {},
   "source": [
    "Eksperimenti su provedeni samo na dijelu Reuters seta. U članku piše da je subset bio veličine 470 dokumenata, od čega je 380 bilo korišteno za treniranje, a 90 za ispitivanje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bad638",
   "metadata": {},
   "source": [
    "U eksperimentu su odabrane kategorij \"earn\", \"acq\", \"crude\" i \"corn\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fca2806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPICS</th>\n",
       "      <th>BODY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>champion products said board directors approve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>dlrs assets deposits loans note available year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>ohio mattress said first quarter ending februa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>oper loss profit seven oper profit profit revs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>revs nine mths dlrs dlrs revs billion reuter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TOPICS                                               BODY\n",
       "19  'earn'  champion products said board directors approve...\n",
       "21  'earn'  dlrs assets deposits loans note available year...\n",
       "22  'earn'  ohio mattress said first quarter ending februa...\n",
       "24  'earn'  oper loss profit seven oper profit profit revs...\n",
       "25  'earn'      revs nine mths dlrs dlrs revs billion reuter "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earn_clanci = dataframe[dataframe.TOPICS.str.contains(\"earn\")]\n",
    "acq_clanci = dataframe[dataframe.TOPICS.str.contains(\"acq\")]\n",
    "crude_clanci = dataframe[dataframe.TOPICS.str.contains(\"crude\")]\n",
    "corn_clanci = dataframe[dataframe.TOPICS.str.contains(\"corn\")]\n",
    "\n",
    "clanci = [earn_clanci, acq_clanci, crude_clanci, corn_clanci]\n",
    "earn_clanci.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1e278",
   "metadata": {},
   "source": [
    "Navedeno je da je broj članaka za pojedinu kategoriju za učenje (ispitivanje) sljedeći:\n",
    "1. earn 152 (40)\n",
    "2. acquisition 114 (25)\n",
    "3. crude 76 (15)\n",
    "4. corn 38 (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f154e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPICS</th>\n",
       "      <th>BODY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8663</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>caesars world said directors unanimously appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>loss five loss loss loss sales shrs year loss ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>advo system said could report break even secon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>loss dlrs loss loss loss revs nine mths loss d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>oper oper revs shrs mths oper oper revs shrs n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>'corn'</td>\n",
       "      <td>french operators have requested licences expor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7964</th>\n",
       "      <td>'corn'</td>\n",
       "      <td>japan appears relying less corn from china arg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5328</th>\n",
       "      <td>'corn'</td>\n",
       "      <td>rain over wide areas raised prospect good food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>'corn'</td>\n",
       "      <td>french operators last friday requested licence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>'corn'</td>\n",
       "      <td>agriculture department usda figures highly ero...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TOPICS                                               BODY\n",
       "8663   'earn'  caesars world said directors unanimously appro...\n",
       "4287   'earn'  loss five loss loss loss sales shrs year loss ...\n",
       "2039   'earn'  advo system said could report break even secon...\n",
       "784    'earn'  loss dlrs loss loss loss revs nine mths loss d...\n",
       "128    'earn'  oper oper revs shrs mths oper oper revs shrs n...\n",
       "...       ...                                                ...\n",
       "6330   'corn'  french operators have requested licences expor...\n",
       "7964   'corn'  japan appears relying less corn from china arg...\n",
       "5328   'corn'  rain over wide areas raised prospect good food...\n",
       "374    'corn'  french operators last friday requested licence...\n",
       "3228   'corn'  agriculture department usda figures highly ero...\n",
       "\n",
       "[380 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "[earn_train, earn_test] = train_test_split(earn_clanci, train_size=152/len(earn_clanci), test_size=40/len(earn_clanci))\n",
    "[acq_train, acq_test] = train_test_split(acq_clanci, train_size=114/len(acq_clanci), test_size=25/len(acq_clanci))\n",
    "[crude_train, crude_test] = train_test_split(crude_clanci, train_size=76/len(crude_clanci), test_size=15/len(crude_clanci))\n",
    "[corn_train, corn_test] = train_test_split(corn_clanci, train_size=38/len(corn_clanci), test_size=10/len(corn_clanci))\n",
    "\n",
    "y_train = []\n",
    "y_train.extend(['earn' for i in range(0, len(earn_train))])\n",
    "y_train.extend(['acq' for i in range(0, len(acq_train))])\n",
    "y_train.extend(['crude' for i in range(0, len(crude_train))])\n",
    "y_train.extend(['corn' for i in range(0, len(corn_train))])\n",
    "y_train = np.array(y_train)\n",
    "#print(y_train)\n",
    "\n",
    "y_test = []\n",
    "y_test.extend(['earn' for i in range(0, len(earn_test))])\n",
    "y_test.extend(['acq' for i in range(0, len(acq_test))])\n",
    "y_test.extend(['crude' for i in range(0, len(crude_test))])\n",
    "y_test.extend(['corn' for i in range(0, len(corn_test))])\n",
    "y_test = np.array(y_test)\n",
    "#print(y_test)\n",
    "\n",
    "clanci_train = [earn_train, acq_train, crude_train, corn_train]\n",
    "clanci_train = pd.concat(clanci_train)\n",
    "clanci_train.to_csv(\"clanci_train.csv\")\n",
    "clanci_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee86bf1",
   "metadata": {},
   "source": [
    "### Effectiveness of Varying Sequence Length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc05ef",
   "metadata": {},
   "source": [
    "Za svaku vrijednost k, eksperiment je proveden 10 puta i onda su dobivene vrijednosti mean i sd. Lambda je postavljen na 0.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ef083d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSK, category = earn\n",
      "k\tmean(F1)\tSTD(F1)\t\tmean(precision)\t\tSTD(precision)\t\tmean(recall)\t\tSTD(recall)\n",
      "['caesars', 'world', 'said', 'directors', 'unanimously', 'approved', 'recapitalization', 'plan', 'under', 'which', 'stockholders', 'will', 'cash', 'distribution', 'dlrs', 'share', 'time', 'special', 'cash', 'dividend', 'will', 'retain', 'their', 'common', 'stock', 'ownership', 'caesars', 'world', 'caesars', 'world', 'said', 'expects', 'raise', 'approximately', 'billion', 'dlrs', 'needed', 'share', 'dividend', 'expenses', 'recapitalization', 'through', 'around', 'dlrs', 'bank', 'borrowings', 'public', 'sale', 'approximately', 'dlrs', 'debt', 'some', 'outstanding', 'debt', 'will', 'retired', 'drexel', 'burnham', 'lambert', 'caesars', 'financial', 'advisor', 'told', 'company', 'confident', 'arrange', 'entire', 'financing', 'needed', 'recapitalization', 'henry', 'gluck', 'chairman', 'chief', 'executive', 'officer', 'hotel', 'casino', 'resorts', 'company', 'said', 'statement', 'board', 'believes', 'recapitalization', 'plan', 'financially', 'superior', 'share', 'tender', 'offer', 'martin', 'sosnoff', 'gluck', 'said', 'caesars', 'world', 'board', 'once', 'again', 'recommends', 'that', 'shareholders', 'reject', 'sosnoff', 'offer', 'stock', 'closed', 'dlrs', 'share', 'friday', 'ability', 'restructure', 'along', 'these', 'lines', 'possible', 'primarily', 'because', 'financial', 'stability', 'strong', 'operating', 'results', 'achieved', 'management', 'recent', 'years', 'gluck', 'said', 'said', 'that', 'after', 'recapitalization', 'takes', 'effect', 'proforma', 'income', 'fiscal', 'year', 'ended', 'july', 'expected', 'about', 'dlrs', 'fiscal', 'primary', 'earnings', 'share', 'projected', 'cents', 'based', 'about', 'post', 'recapitalization', 'common', 'common', 'equivalent', 'shares', 'outstanding', 'commenting', 'companys', 'longer', 'term', 'earnings', 'outlook', 'gluck', 'said', 'project', 'income', 'increase', 'dlrs', 'reflecting', 'increased', 'operating', 'income', 'lower', 'interest', 'expense', 'retirement', 'dlrs', 'debt', 'incurred', 'connection', 'with', 'recapitalization', 'said', 'company', 'does', 'usually', 'release', 'projections', 'done', 'beause', 'significance', 'recapitalization', 'gluck', 'said', 'recapitalization', 'plan', 'will', 'submitted', 'stockholder', 'approval', 'special', 'meeting', 'expected', 'june', 'plan', 'will', 'require', 'approval', 'stockholders', 'that', 'nevada', 'jersey', 'gaming', 'regulatory', 'authorities', 'part', 'plan', 'company', 'will', 'change', 'state', 'incorporation', 'from', 'florida', 'delaware', 'means', 'merger', 'caesars', 'world', 'into', 'wholly', 'owned', 'subsidiary', 'company', 'incorporation', 'certificate', 'bylaws', 'will', 'provide', 'among', 'other', 'things', 'fair', 'price', 'provision', 'requiring', 'that', 'certain', 'transactions', 'with', 'interested', 'stockholders', 'approved', 'vote', 'stockholders', 'excluding', 'shares', 'held', 'such', 'interested', 'stockholders', 'caesars', 'world', 'said', 'statement', 'that', 'cash', 'distribution', 'will', 'result', 'substantial', 'deficit', 'stockholders', 'equity', 'give', 'estimate', 'size', 'this', 'deficit', 'company', 'said', 'financial', 'advisors', 'have', 'said', 'they', 'believe', 'that', 'after', 'recapitalization', 'caesars', 'world', 'should', 'have', 'financial', 'flexibility', 'resources', 'necessary', 'finance', 'current', 'projected', 'operating', 'capital', 'requirements', 'reuter']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only single character unicode strings can be converted to Py_UCS4, got length 7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [43], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m         recall_sd \u001b[38;5;241m=\u001b[39m std(recall)\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k, f1_mean, f1_std, precision_mean, precision_sd, recall_mean, recall_sd))   \n\u001b[1;32m---> 46\u001b[0m \u001b[43mssk_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mearn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearn_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mearn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mearn_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m ssk_evaluation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macq\u001b[39m\u001b[38;5;124m\"\u001b[39m, acq_test, np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macq\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(acq_test))]), k_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m14\u001b[39m))\n\u001b[0;32m     48\u001b[0m ssk_evaluation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrude\u001b[39m\u001b[38;5;124m\"\u001b[39m, crude_test, np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrude\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(crude_test))]), k_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m14\u001b[39m))\n",
      "Cell \u001b[1;32mIn [43], line 29\u001b[0m, in \u001b[0;36mssk_evaluation\u001b[1;34m(category, X_test, y_true, k_range)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_range[\u001b[38;5;241m0\u001b[39m], k_range[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     28\u001b[0m     ssk_model \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39mstring_kernel(n\u001b[38;5;241m=\u001b[39mk, lbda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m))\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mssk_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtreniranje\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_treniranje\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     f1 \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     31\u001b[0m     precision \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:255\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    254\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 255\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# you must store a reference to X to compute the kernel in predict\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;66;03m# TODO: add keyword copy to copy on demand\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__Xfit \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m--> 297\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[0] should be equal to X.shape[1]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:493\u001b[0m, in \u001b[0;36mBaseLibSVM._compute_kernel\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03m\"\"\"Return the data transformed by a callable kernel\"\"\"\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;66;03m# in the case of precomputed kernel given as a function, we\u001b[39;00m\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;66;03m# have to compute explicitly the kernel matrix\u001b[39;00m\n\u001b[1;32m--> 493\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__Xfit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(kernel):\n\u001b[0;32m    495\u001b[0m         kernel \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32m~\\Documents\\FER\\Uvod u znanost o podacima\\Text Classification using String Kernels\\string_kernel.pyx:79\u001b[0m, in \u001b[0;36mstring_kernel.string_kernel.kernel\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m for i in range(lenxs):\n\u001b[0;32m     78\u001b[0m     for j in range(i,lenys):\n\u001b[1;32m---> 79\u001b[0m         mat[j,i] = mat[i,j] = ssk_fun(_xs[i,0], _ys[j,0], n, lbda, accum=True)\n\u001b[0;32m     80\u001b[0m \n\u001b[0;32m     81\u001b[0m mat_xs = mat_ys = mat.diagonal().reshape((lenxs, 1))\n",
      "File \u001b[1;32m~\\Documents\\FER\\Uvod u znanost o podacima\\Text Classification using String Kernels\\string_kernel.pyx:12\u001b[0m, in \u001b[0;36mstring_kernel.ssk\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \"\"\"s and t are strings, either numpy.str_ or python str, or a list of chars\"\"\"\n\u001b[0;32m     11\u001b[0m print(s)\n\u001b[1;32m---> 12\u001b[0m s_array = array.array('l', [ord(c) for c in s])\n\u001b[0;32m     13\u001b[0m t_array = array.array('l', [ord(c) for c in t])\n\u001b[0;32m     14\u001b[0m return ssk_array(s_array, t_array, n, lbda, accum)\n",
      "\u001b[1;31mValueError\u001b[0m: only single character unicode strings can be converted to Py_UCS4, got length 7"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def ssk_evaluation(category, X_test, y_true, k_range=(5, 5)):\n",
    "    print(\"SSK, category =\", category)\n",
    "    print(\"k\\tmean(F1)\\tSTD(F1)\\t\\tmean(precision)\\t\\tSTD(precision)\\t\\tmean(recall)\\t\\tSTD(recall)\")\n",
    "    treniranje = []\n",
    "    for index, row in clanci_train.iterrows():\n",
    "        ''.join(r'\\u{:04X}'.format(ord(chr)) for chr in test_str)\n",
    "        lista = row['BODY'].split(\" \")\n",
    "        lista = [el for el in lista if el != '']\n",
    "        treniranje.append(lista)\n",
    "    treniranje = np.array(treniranje)\n",
    "    treniranje = treniranje.reshape(len(treniranje), 1)\n",
    "    y_treniranje = y_train.reshape(len(y_train), 1)\n",
    "    \n",
    "    testiranje = []\n",
    "    for index, row in X_test.iterrows():\n",
    "        lista = row['BODY']#.split(\" \")\n",
    "        testiranje.append(lista)\n",
    "    testiranje = np.array(testiranje)\n",
    "    testiranje = testiranje.reshape(len(testiranje), 1)\n",
    "    y_true = y_true.reshape(len(y_true), 1)\n",
    "    \n",
    "    #print(treniranje)\n",
    "    for k in range(k_range[0], k_range[1]+1):\n",
    "        ssk_model = SVC(kernel=string_kernel(n=k, lbda=0.5))\n",
    "        ssk_model.fit(treniranje, y_treniranje)\n",
    "        f1 = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        for i in range(0, 10):\n",
    "            y_pred = ssk_model.predict(testiranje)\n",
    "            f1.append(f1_score(y_true, y_pred))\n",
    "            precision.append(precision(y_true, y_pred))\n",
    "            recall.append(precision(y_true, y_pred))\n",
    "        f1_mean = mean(f1)\n",
    "        f1_sd = std(f1)\n",
    "        precision_mean = mean(precision)\n",
    "        precision_sd = std(precision)\n",
    "        recall_mean = mean(recall)\n",
    "        recall_sd = std(recall)\n",
    "        print(\"{}\\t{}\\t{}\\t\\t{}\\t\\t{}\\t\\t{}\\t\\t{}\\n\".format(k, f1_mean, f1_std, precision_mean, precision_sd, recall_mean, recall_sd))   \n",
    "\n",
    "ssk_evaluation(\"earn\", earn_test, np.array(['earn' for i in range(0, len(earn_test))]), k_range=(3, 14))\n",
    "ssk_evaluation(\"acq\", acq_test, np.array(['acq' for i in range(0, len(acq_test))]), k_range=(3, 14))\n",
    "ssk_evaluation(\"crude\", crude_test, np.array(['crude' for i in range(0, len(crude_test))]), k_range=(3, 14))\n",
    "ssk_evaluation(\"corn\", corn_test, np.array(['corn' for i in range(0, len(corn_test))]), k_range=(3, 14))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ee940",
   "metadata": {},
   "source": [
    "### Effectiveness of Varying Weight Decay Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6587c1e8",
   "metadata": {},
   "source": [
    "k je postavljen na 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2eeff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fb2ccae",
   "metadata": {},
   "source": [
    "### Effectiveness of Combining Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c6228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64646598",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90779903",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MOJ SSK\n",
    "\n",
    "import itertools\n",
    "\n",
    "# SSK - string subsequence kernel\n",
    "def is_subsequence(subsequence, word):\n",
    "    iterator = iter(word)\n",
    "    if all(c in iterator for c in subsequence):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ssk_kernel(string1, string2, k=2, lambd=1):\n",
    "    stupci = []\n",
    "    tablica = {}\n",
    "\n",
    "    for word in [string1, string2]:\n",
    "        letters = list(word)\n",
    "        for combination in itertools.combinations(letters, k): # nalazi sve kombinacije slova u letters duljine k\n",
    "            s = ''.join(combination)\n",
    "            if s not in stupci:\n",
    "                stupci.append(s)\n",
    "    \n",
    "    #print(stupci)\n",
    "\n",
    "    for word in [string1, string2]:\n",
    "        tablica[word] = [0 for i in range(len(stupci))]\n",
    "        subsequence_index = 0\n",
    "        for stupac in stupci:\n",
    "            if is_subsequence(stupac, word):\n",
    "                cell_rez = 1\n",
    "                index_slova_rijeci = 0\n",
    "                for index_slova_stupca in range(len(stupac) - 1):\n",
    "                    cell_rez += word.index(stupac[index_slova_stupca+1], word.index(stupac[index_slova_stupca])+1)-word.index(stupac[index_slova_stupca])\n",
    "                tablica[word][subsequence_index] = pow(lambd, cell_rez)\n",
    "                #print(word, tablica[word])\n",
    "                # res += i.index(j[ki+1], i.index(j[ki])+1)-i.index(j[ki])\n",
    "            subsequence_index += 1\n",
    "\n",
    "    red_1 = np.array(tablica[string1])\n",
    "    red_2 = np.array(tablica[string2])\n",
    "    rez_1 = np.sum(red_1*red_2.T)\n",
    "    rez_2 = np.sum(red_1*red_1.T)\n",
    "    rez_3 = np.sum(red_2*red_2.T)\n",
    "    rez = rez_1/pow(rez_2*rez_3, 0.5)\n",
    "\n",
    "    return rez\n",
    "\n",
    "print(ssk_kernel(\"car\", \"cat\", lambd=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2070e10",
   "metadata": {},
   "source": [
    "Ako treniramo modele s punim člancima, onda radi presporo tako da sam odlučila iz svakog članka izdvojiti n = *** najčešćih riječi i onda po njima uspoređivati članke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b879be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def return_n_most_common_words(row, n):\n",
    "    words_in_row = row['BODY'].split(\" \")\n",
    "    count = Counter()\n",
    "    for word in words_in_row:\n",
    "        if len(word) > 3:\n",
    "            count[word] += 1\n",
    "    lista = np.array([])\n",
    "    for (element, _) in count.most_common(n):\n",
    "        lista = np.append(lista, element)\n",
    "    #row['MOST_COMMON'] = lista\n",
    "    #print(lista)\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5b84076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPICS</th>\n",
       "      <th>BODY</th>\n",
       "      <th>MOST_COMMON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>champion products inc said its board of direct...</td>\n",
       "      <td>[said, board, stock, shares, shareholders, apr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr    cts vs      dlrs     net         vs    ...</td>\n",
       "      <td>[dlrs, assets, deposits, loans, note, availabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>ohio mattress co said its first quarter  endin...</td>\n",
       "      <td>[said, quarter, first, acquisitions, dlrs, sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>oper shr loss two cts vs profit seven cts     ...</td>\n",
       "      <td>[profit, oper, loss, revs, shrs, mths, seven, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr one dlr vs    cts     net      mln vs     ...</td>\n",
       "      <td>[revs, dlrs, nine, mths, billion, reuter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13058</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr loss nine cts vs loss    cts     net loss ...</td>\n",
       "      <td>[loss, dlrs, capitalized, costs, nine, revs, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13059</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr    cts vs    cts     shr diluted    cts vs...</td>\n",
       "      <td>[diluted, shrs, sales, nine, mths, dlrs, reuter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13060</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>shr    cts vs    cts     net      mln vs      ...</td>\n",
       "      <td>[dlrs, sales, shrs, nine, mths, oper, billion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13103</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>nine months ended august        group shr     ...</td>\n",
       "      <td>[billion, group, nine, months, ended, august, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13104</th>\n",
       "      <td>'earn'</td>\n",
       "      <td>third quarter ended august        group shr   ...</td>\n",
       "      <td>[billion, group, third, quarter, ended, august...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3776 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TOPICS                                               BODY  \\\n",
       "19     'earn'  champion products inc said its board of direct...   \n",
       "21     'earn'  shr    cts vs      dlrs     net         vs    ...   \n",
       "22     'earn'  ohio mattress co said its first quarter  endin...   \n",
       "24     'earn'  oper shr loss two cts vs profit seven cts     ...   \n",
       "25     'earn'  shr one dlr vs    cts     net      mln vs     ...   \n",
       "...       ...                                                ...   \n",
       "13058  'earn'  shr loss nine cts vs loss    cts     net loss ...   \n",
       "13059  'earn'  shr    cts vs    cts     shr diluted    cts vs...   \n",
       "13060  'earn'  shr    cts vs    cts     net      mln vs      ...   \n",
       "13103  'earn'  nine months ended august        group shr     ...   \n",
       "13104  'earn'  third quarter ended august        group shr   ...   \n",
       "\n",
       "                                             MOST_COMMON  \n",
       "19     [said, board, stock, shares, shareholders, apr...  \n",
       "21     [dlrs, assets, deposits, loans, note, availabl...  \n",
       "22     [said, quarter, first, acquisitions, dlrs, sea...  \n",
       "24     [profit, oper, loss, revs, shrs, mths, seven, ...  \n",
       "25             [revs, dlrs, nine, mths, billion, reuter]  \n",
       "...                                                  ...  \n",
       "13058  [loss, dlrs, capitalized, costs, nine, revs, s...  \n",
       "13059   [diluted, shrs, sales, nine, mths, dlrs, reuter]  \n",
       "13060  [dlrs, sales, shrs, nine, mths, oper, billion,...  \n",
       "13103  [billion, group, nine, months, ended, august, ...  \n",
       "13104  [billion, group, third, quarter, ended, august...  \n",
       "\n",
       "[3776 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earn_clanci['MOST_COMMON'] = earn_clanci.apply(lambda row: return_n_most_common_words(row, n=50), axis=1)\n",
    "acq_clanci['MOST_COMMON'] = acq_clanci.apply(lambda row: return_n_most_common_words(row, n=50), axis=1)\n",
    "crude_clanci['MOST_COMMON'] = crude_clanci.apply(lambda row: return_n_most_common_words(row, n=50), axis=1)\n",
    "corn_clanci['MOST_COMMON'] = corn_clanci.apply(lambda row: return_n_most_common_words(row, n=50), axis=1)\n",
    "earn_clanci"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "52ff7c03b8138598d26f7db6d70fd0156ea4d6d9d9b70d008337a8032a894406"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
