{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sveučilište u Zagrebu<br>\n",
    "Fakultet elektrotehnike i računarstva\n",
    "\n",
    "## Uvod u znanost o podacima\n",
    "\n",
    "\n",
    "# Priprema i vizualizacija podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prikaz podataka o datotekama i člancima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'reuters21578'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreuters21578\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFILENAME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEWID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOLDID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLEWISSPLIT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCGISPLIT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOPICS_ENUM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTEXT TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTITLE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUTHOR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATELINE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOPICS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPLACES\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPEOPLE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORGS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEXCHANGES\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOMPANIES\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBODY\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'reuters21578'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "files = os.listdir('reuters21578')\n",
    "\n",
    "columns = ['FILENAME', 'NEWID', 'OLDID', 'LEWISSPLIT', 'CGISPLIT', 'TOPICS_ENUM', 'TEXT TYPE', 'DATE', 'TITLE', 'AUTHOR', 'DATELINE', 'TOPICS', 'PLACES', 'PEOPLE', 'ORGS', 'EXCHANGES', 'COMPANIES',  'BODY']\n",
    "rows = []\n",
    "\n",
    "for filename in os.listdir('reuters21578'):\n",
    "    if filename.endswith(\".sgm\"):\n",
    "        file_content = open(os.path.join(\"reuters21578\", filename), mode = 'r', encoding='ascii', errors='ignore').read()\n",
    "        articles = file_content.split(\"</REUTERS>\")\n",
    "        articles[0] = articles[0][articles[0].find(\"\\n\")::] ## izbacimo prvi red, onaj <!DOCSTYLE ...\n",
    "        #print(articles[0])\n",
    "        \n",
    "        for article in articles:\n",
    "            if \"<REUTERS\" in article:\n",
    "                red = {}\n",
    "                red['FILENAME'] = filename\n",
    "                red['NEWID'] = re.findall('NEWID=\"([^\"]*)\"', article)[0]\n",
    "                red['OLDID'] = re.findall('OLDID=\"([^\"]*)\"', article)[0]\n",
    "                red['TOPICS_ENUM'] = re.findall('TOPICS=\"([^\"]*)\"', article)[0]\n",
    "                red['TEXT TYPE'] = \"\".join(re.findall('TEXT TYPE=\"([^\"]*)\"', article))\n",
    "                red['LEWISSPLIT'] = re.findall('LEWISSPLIT=\"([^\"]*)\"', article)[0]\n",
    "                red['CGISPLIT'] = re.findall('CGISPLIT=\"([^\"]*)\"', article)[0]\n",
    "                for znacajka in columns[7:]:\n",
    "                    if znacajka == \"DATE\":\n",
    "                        regex = '<' + znacajka + '>' + '([^&#$]*)' + '</' + znacajka + '>'\n",
    "                    else:\n",
    "                        regex = '<' + znacajka + '>' + '([\\s\\S]*)' + '</' + znacajka + '>'\n",
    "                    match = re.findall(regex, article)\n",
    "                    if(len(match)==0):\n",
    "                        continue\n",
    "                    elif match[0] == '':\n",
    "                        continue\n",
    "                    else:\n",
    "                        match = match[0]\n",
    "                        if '<D>' in match:\n",
    "                            match = match.replace('<D>', '')\n",
    "                            match = match.split('</D>')\n",
    "                            match = match[:-1]\n",
    "                        red[znacajka] = match\n",
    "                #print(red[0:-1])\n",
    "                rows.append(red.copy())\n",
    "\n",
    "dataframe = pd.DataFrame(rows, columns=['NEWID', 'TOPICS', 'PLACES', 'PEOPLE', 'ORGS', 'EXCHANGES', 'TITLE', 'AUTHOR', 'DATELINE', 'OLDID', 'TOPICS_ENUM', 'FILENAME', 'DATE', 'COMPANIES', 'BODY', 'TEXT TYPE', 'LEWISSPLIT', 'CGISPLIT'])\n",
    "dataframe = dataframe.astype('string')\n",
    "dataframe = dataframe.astype({'NEWID' : 'int64', 'OLDID' : 'int64'})\n",
    "#dataframe = dataframe.set_index(\"NEWID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prikaz prvih 10 redova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pohrana Dataframe-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"clanci.csv\"\n",
    "dataframe.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clanci = pd.read_csv(filename, index_col = 0)\n",
    "clanci.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregled podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broj_primjeraka, broj_znacajki = clanci.shape\n",
    "print(\"broj primjeraka (članaka), N = {}\".format(broj_primjeraka))\n",
    "print(\"broj značajki, n = {}\".format(broj_znacajki))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Koliko članaka ima u svakoj datoteci:\")\n",
    "print(clanci.groupby('FILENAME').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Značajke:\n",
    "- **newid** - id koji članak ima u Reuters-21578 klasifikaciji\n",
    "- **topics** - lista kategorija tema kojima članak pripada\n",
    "- **places** - lista kategorija mjesta kojima članak pripada\n",
    "- **people** - lista kategorija ljudi kojima članak pripada\n",
    "- **orgs** - lista kategorija orgs kojima članak pripada\n",
    "- **exchange** - lista kategorija razmjena kojima članak pripada\n",
    "- **title** - naslov članka\n",
    "- **author** - autor teksta\n",
    "- **dateline** - od kod je članak potekao, i dan u godini\n",
    "- **oldid** - id koji je članak imao u Reuters-22173 klasifikaciji\n",
    "- **topics enum** - moguće vrijednosti su [YES, NO, BYPASS], je li dokument imao topics kategoriju u originalnom datasetu\n",
    "- **filename** - ime datoteke u kojoj se nalazi članak\n",
    "- **date** - datum i vrijeme dokumenta\n",
    "- **companies** - ?\n",
    "- **body** - tijelo teksta\n",
    "- **text type** - moguće vrijednosti su [NORM, BRIEF, UNPROC], norm znači da tekst ima normalnu strukturu, brief znači da je tekst kratak, unproc znači da tekst ima neobičnu strukturu\n",
    "- **lewissplit** - moguće vrijednosti su [TRAINING, TEST, NOT_USED] ovisno o tome za što se članak koristio u eksperimentima u izvješćima: LEWIS91d (poglavlja 9 i 10), LEWIS92b, LEWIS92e i LEWIS94b\n",
    "- **cgisplit** - moguće vrijednosti su [TRAINING-SET, PUBLISHED-TESTSET] ovisno o tome za što se članak koristi u eksperimentima  u izvješćima HAYES89 i HAYES90b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monotoni atributi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.nunique() # gledamo ako ima monotonih značajki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaključujemo da su NEWID i OLDID monotone značajke. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = dataframe.copy() #čuvamo original podataka, just in case\n",
    "podaci = original.copy()\n",
    "\n",
    "podaci = podaci.drop('OLDID', axis=1, inplace=False)\n",
    "podaci.drop('NEWID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podaci.isna().sum() # broji nul vrijednosti za značajke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidimo da osim značajki za klasifikacijske oznake (topics, places, people, orgs, exchanges), značajke AUTHOR i COMPANIES imaju puno nul vrijednosti. Izbacujemo te značajke iz skupa podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podaci.drop(['AUTHOR', 'COMPANIES'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izbacujemo zapise koji nemaju body jer nam oni zapravo ništa ne govore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podaci = podaci.loc[podaci.BODY.notnull(), :] # zadržavamo samo one zapise kojima body nije null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoder\n",
    "Mijenjamo format značajki koje imaju malo unique vrijednosti (poprimaju vrijednosti iz nekog diskretnog skupa) - topics_enum, text type, lewisspit, cgisplit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(podaci.loc[:, 'TOPICS_ENUM'])\n",
    "podaci.loc[:, 'TOPICS_ENUM'] = le.transform(podaci.loc[:, 'TOPICS_ENUM'])\n",
    "le.fit(podaci.loc[:, 'TEXT TYPE'])\n",
    "podaci.loc[:, 'TEXT TYPE'] = le.transform(podaci.loc[:, 'TEXT TYPE'])\n",
    "le.fit(podaci.loc[:, 'LEWISSPLIT'])\n",
    "podaci.loc[:, 'LEWISSPLIT'] = le.transform(podaci.loc[:, 'LEWISSPLIT'])\n",
    "le.fit(podaci.loc[:, 'CGISPLIT'])\n",
    "podaci.loc[:, 'CGISPLIT'] = le.transform(podaci.loc[:, 'CGISPLIT'])\n",
    "podaci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podaci.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualizacija podataka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_per_lewissplit = clanci.groupby('LEWISSPLIT').count().loc[:, 'NEWID'].values\n",
    "labels = clanci.groupby('LEWISSPLIT').count().index.values\n",
    "percent = (count_per_lewissplit/len(clanci))*100\n",
    "\n",
    "# pokazuje postotak članaka koji su se koristi u kojim skupinama\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.pie(percent, labels=labels, autopct='%.2f')\n",
    "plt.title(\"Udio podataka za treniranje i testiranje, LEWIS SPLIT\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inkonzistentni podaci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inkonzistentni podaci\n",
    "dateline_helper_dataframe = podaci.copy()\n",
    "dateline_helper_dataframe['DATELINE'] = dateline_helper_dataframe.DATELINE.str.upper()\n",
    "dateline_helper_dataframe['DATELINE'] = dateline_helper_dataframe.DATELINE.str.replace('JANUARY', 'JAN')\n",
    "dateline_helper_dataframe['DATELINE'] = dateline_helper_dataframe.DATELINE.str.upper().str.replace('FEBRUARY', 'FEB')\n",
    "dateline_helper_dataframe['DATELINE'] = dateline_helper_dataframe.DATELINE.str.replace('MARCH', 'MAR').str.replace('NARCH', 'MAR')\n",
    "dateline_helper_dataframe['DATELINE'] = dateline_helper_dataframe.DATELINE.str.replace('APRIL', 'APR')\n",
    "dateline_helper_dataframe['DATELINE'] = dateline_helper_dataframe.DATELINE.str.replace('JUNE', 'JUN')\n",
    "dateline_helper_dataframe['DATELINE'] = dateline_helper_dataframe.DATELINE.str.replace('JULY', 'JUL')\n",
    "dateline_helper_dataframe['DATELINE'] = dateline_helper_dataframe.DATELINE.str.replace('AUGUST', 'AUG')\n",
    "dateline_helper_dataframe['DATELINE'] = dateline_helper_dataframe.DATELINE.str.replace('SEPTEMBER', 'SEP')\n",
    "dateline_helper_dataframe['DATELINE'] = dateline_helper_dataframe.DATELINE.str.replace('OCTOBER', 'OCT')\n",
    "dateline_helper_dataframe['DATELINE'] = dateline_helper_dataframe.DATELINE.str.replace('NOVEMBER', 'NOV')\n",
    "dateline_helper_dataframe['DATELINE'] = dateline_helper_dataframe.DATELINE.str.replace('DECEMBER', 'DEC')\n",
    "\n",
    "\n",
    "dateline_helper_dataframe = dateline_helper_dataframe.loc[dateline_helper_dataframe.DATELINE.notnull(), :]\n",
    "dateline_helper_dataframe = dateline_helper_dataframe.DATELINE.str.extract(r',[\\s]*(\\w+)[\\s]*[\\d]*[\\s]*-')\n",
    "dateline_helper_dataframe = dateline_helper_dataframe.loc[dateline_helper_dataframe[0].notnull(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"]\n",
    "count_months = {}\n",
    "for month in months:\n",
    "    count_months[month] = 0\n",
    "    \n",
    "nul = 0\n",
    "for month in dateline_helper_dataframe.to_numpy():\n",
    "    try:\n",
    "        count_months[month[0]] += 1\n",
    "    except:\n",
    "        nul += 1\n",
    "\n",
    "#print(count_months)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(count_months.keys(), count_months.values())\n",
    "plt.grid()\n",
    "plt.title(\"Broj objavljenih članaka po mjesecima u 1987. godini\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podaci o kategorijama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchanges = []\n",
    "orgs = []\n",
    "people = []\n",
    "places = []\n",
    "topics = []\n",
    "\n",
    "\n",
    "file_content = open(os.path.join(\"reuters21578\", \"all-exchanges-strings.lc.txt\"), mode = 'r').read()\n",
    "exchanges = file_content.split(\"\\n\")\n",
    "file_content = open(os.path.join(\"reuters21578\", \"all-orgs-strings.lc.txt\"), mode = 'r').read()\n",
    "orgs = file_content.split(\"\\n\")\n",
    "file_content = open(os.path.join(\"reuters21578\", \"all-people-strings.lc.txt\"), mode = 'r').read()\n",
    "people = file_content.split(\"\\n\")\n",
    "file_content = open(os.path.join(\"reuters21578\", \"all-places-strings.lc.txt\"), mode = 'r').read()\n",
    "places = file_content.split(\"\\n\")\n",
    "file_content = open(os.path.join(\"reuters21578\", \"all-topics-strings.lc.txt\"), mode = 'r').read()\n",
    "topics = file_content.split(\"\\n\")\n",
    "\n",
    "#print(\"Sve moguće vrijednosti klase exchanges:\\n\", exchanges)\n",
    "#print(\"Sve moguće vrijednosti klase orgs:\\n\", orgs)\n",
    "#print(\"Sve moguće vrijednosti klase people:\\n\", people)\n",
    "#print(\"Sve moguće vrijednosti klase places:\\n\", places)\n",
    "#print(\"Sve moguće vrijednosti klase topics:\\n\", topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_topic = {}\n",
    "for topic in topics:\n",
    "    most_freq_topic[topic] = dataframe.TOPICS.str.contains(topic).sum()\n",
    "\n",
    "del most_freq_topic['']\n",
    "topic_map_top_10 = dict(sorted(most_freq_topic .items(), key=lambda x: -x[1])[0:10]) #sortiramo od najčešćeg topica prema manje čestima\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(topic_map_top_10.keys(), topic_map_top_10.values())\n",
    "plt.title(\"10 ukupno najčešćih topic-a\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "count_topic_train = {}\n",
    "count_topic_test = {}\n",
    "for topic in topic_map_top_10.keys():\n",
    "    count_topic_train[topic] = dataframe[dataframe.LEWISSPLIT == \"TRAIN\"].TOPICS.str.contains(topic).sum()\n",
    "    count_topic_test[topic] =  dataframe[dataframe.LEWISSPLIT == \"TEST\"].TOPICS.str.contains(topic).sum()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.grid()\n",
    "plt.bar(topic_map_top_10.keys(), count_topic_train.values(), color='red', label='TRAIN')\n",
    "plt.bar(topic_map_top_10.keys(), count_topic_test.values(), color='green', label='TEST', bottom=list(count_topic_train.values())) # bottom -> postavi vrijednost NA count_per_title_died\n",
    "plt.title(\"Udio podataka s određenom klasom u train/test setu\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_exchanges = {}\n",
    "for exchange in exchanges:\n",
    "    most_freq_exchanges[exchange] = dataframe.EXCHANGES.str.contains(exchange).sum()\n",
    "\n",
    "del most_freq_exchanges['']\n",
    "exchanges_map_top_10 = dict(sorted(most_freq_exchanges.items(), key=lambda x: -x[1])[0:10]) #sortiramo od najčešćeg topica prema manje čestima\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(exchanges_map_top_10.keys(), exchanges_map_top_10.values())\n",
    "plt.title(\"10 ukupno najčešćih exchange-a\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_people = {}\n",
    "for p in people:\n",
    "    most_freq_people[p] = dataframe.PEOPLE.str.contains(p).sum()\n",
    "\n",
    "del most_freq_people['']\n",
    "people_map_top_10 = dict(sorted(most_freq_people.items(), key=lambda x: -x[1])[0:10]) #sortiramo od najčešćeg topica prema manje čestima\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(people_map_top_10.keys(), people_map_top_10.values())\n",
    "plt.title(\"10 ukupno najčešćih people-a\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_places = {}\n",
    "for p in places:\n",
    "    most_freq_places[p] = dataframe.PEOPLE.str.contains(p).sum()\n",
    "\n",
    "del most_freq_places['']\n",
    "places_map_top_10 = dict(sorted(most_freq_places.items(), key=lambda x: -x[1])[0:10]) #sortiramo od najčešćeg topica prema manje čestima\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(places_map_top_10.keys(), places_map_top_10.values())\n",
    "plt.title(\"10 ukupno najčešćih places-a\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_orgs = {}\n",
    "for o in orgs:\n",
    "    most_freq_orgs[o] = dataframe.ORGS.str.contains(o).sum()\n",
    "\n",
    "del most_freq_orgs['']\n",
    "orgs_map_top_10 = dict(sorted(most_freq_orgs.items(), key=lambda x: -x[1])[0:10]) #sortiramo od najčešćeg topica prema manje čestima\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(orgs_map_top_10.keys(), orgs_map_top_10.values())\n",
    "plt.title(\"10 ukupno najčešćih orgs-a\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dodavanje stupca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podaci_added = podaci.copy()\n",
    "podaci_added['WORD_COUNT'] = podaci_added.apply(lambda row: len(row.BODY), axis=1)\n",
    "podaci_added.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = (podaci_added.WORD_COUNT.max() - podaci_added.WORD_COUNT.min())/10\n",
    "bins = [podaci_added.WORD_COUNT.min()]\n",
    "xticks = [podaci_added.WORD_COUNT.min()]\n",
    "names = []\n",
    "for i in range(1, 10):\n",
    "    bins.append(int(podaci_added.WORD_COUNT.min()+interval*i))\n",
    "    xticks.append(int(podaci_added.WORD_COUNT.min()+interval*i))\n",
    "    names.append(\" \" + str(int(podaci_added.WORD_COUNT.min() + (i-1)*interval)) + \" - \" + str(int(podaci_added.WORD_COUNT.min() + i*interval)))\n",
    "\n",
    "podaci_added['WORD_COUNT_RANGE'] = pd.cut(podaci_added['WORD_COUNT'], bins, labels=names)\n",
    "\n",
    "plt.hist(podaci_added.WORD_COUNT, color='blue', alpha=0.5)\n",
    "plt.xlabel(\"Broj riječi\")\n",
    "plt.ylabel(\"Broj članaka\")\n",
    "plt.xticks(xticks)\n",
    "plt.xlim(xmax = 7000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kutijasti graf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(podaci_added.WORD_COUNT) # kružići su outliersi, whiskers su min i max vrijednosti, a narančasta crta je srednja vrijednost\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podaci o riječima u tijelima članaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "import nltk as nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = podaci.loc[podaci.BODY.notnull(), :]\n",
    "\n",
    "dataframe['BODY'] = dataframe['BODY'].replace('[\\n\\t0-9]',' ', regex=True) # uklanjamo sve prijelaze u novi red, tabulatore i brojeve iz tijela članaka\n",
    "\n",
    "dataframe['BODY'] = dataframe['BODY'].replace('[\\.\\-\"\\#$%&!/,;]',' ', regex=True) #\n",
    "\n",
    "dataframe['BODY'] = dataframe['BODY'].str.lower()\n",
    "\n",
    "dataframe['BODY'] = dataframe['BODY'].replace('[\\s]', ' ', regex=True)\n",
    "\n",
    "dataframe['BODY'] = dataframe['BODY'].replace('[^a-zA-Z0-9\\n \\.]', '', regex=True)\n",
    "\n",
    "#dataframe['BODY'] = dataframe['BODY'].replace('[^\\x00-\\x7f]', '', regex=True)\n",
    "\n",
    "#dataframe['BODY'] = dataframe['BODY'].encode()\n",
    "\n",
    "from collections import Counter\n",
    "count = Counter()\n",
    "\n",
    "exclude = set(stopwords.words('english'))\n",
    "#print(exclude)\n",
    "\n",
    "for index, row in dataframe.iterrows():\n",
    "    body = []\n",
    "    for w in words_per_row:\n",
    "        if w not in exlude:\n",
    "            body.append(w)\n",
    "    row['BODY'] = body\n",
    "    \n",
    "words_per_row = word_tokenize(dataframe['BODY'].str)\n",
    "for words in words_per_row:\n",
    "    count[word] += 1\n",
    "\n",
    "dataframe.to_csv(\"clanci_stripped.csv\")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.title(\"10 najčešćih riječi\")\n",
    "for item in count.most_common(10):\n",
    "    plt.bar(item[0], item[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
